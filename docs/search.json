[{"path":"/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 CVtreeMLE authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/intro_CVtreeMLE.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Evaluating Causal Effects of Mixed Exposures using Data Adaptive Decision Trees and CV-TMLE","text":"Data adaptive target parameters constitute flexible framework estimating effects data adaptively determined target parameter. literature dangers deriving parameters data-adaptively common approach deriving consistent inference data-adaptively defined parameter use sample-splitting. sample-splitting researcher splits full data training set used define parameter, estimation sample estimates derived given parameter identified training. course approach can costly new samples collected estimation data loses power full data simply split. proposed approach decision tree applied mixtures, aims preserve data-adaptive part sample splitting algorithm define average data-adaptive parameter estimates across estimation samples based arbitrary splits K-fold cross-validation. way, one can still use power entire dataset. CVtreeMLE package implements decision tree algorithms computing thresholds exposures maximize minimize outcome flexibly adjusting covariates. nodes decision tree represented binary exposures targeted minimum loss-based estimates (TMLE) derived counterfactual mean outcome difference individual exposed rule compared observed outcome observed exposure distribution. call estimate , average regional exposure effect. Two types results given region found minimize maximize expected outcome. K-fold specific results given variance estimates fold specific region. pooled takes average across folds gain power (reduce variance). pooled estimates oracle target parameter region maximizes minimizes expected outcome. course can change across folds therefore estimate, inconcistency region estiamted, can lead amalgamation different regions. However, strong signal particular region, exposures used region therefore pooled parameter gains power, leveraging k-fold specific estimates. give researchers can look see consistent rules given sample splitting adds information pooled result. technical presentation, interested reader invited consult (mccoy2022CVtreeMLE?) earlier work van der Laan Rose (2011), van der Laan Rose (2018), van der Laan et al. (2022). background data-adaptive target parameters see Hubbard, Kherad-Pajouh, Van Der Laan (2016) chapter 9 van der Laan Rose (2018). Briefly, package first, given provided data partition data folds based n_folds parameter provided. training fold, apply custom decision tree greedily partitions exposure space, partition uses g-computation estimate expected outcome region controlling covariates. finds region maximizes minimizes expected outcome. done fold. region maximizes minimizes expected outcome fold, estimate effect comparing expected outcome everyone forced region compared observed outcome observed exposure. . done fold also pool across folds. procedure done CV-TMLE. output thresholds accompanying region maximimum minimum expected outcome. start, let’s load packages ’ll need set seed simulation. use real-world data example known ground-truth show functionality CVtreeMLE.","code":"library(data.table) library(CVtreeMLE) library(sl3) library(kableExtra) library(dplyr) library(ggplot2) library(purrr)  seed <- 5454433 set.seed(seed)"},{"path":"/articles/intro_CVtreeMLE.html","id":"national-institute-of-environmental-health-data","dir":"Articles","previous_headings":"","what":"National Institute of Environmental Health Data","title":"Evaluating Causal Effects of Mixed Exposures using Data Adaptive Decision Trees and CV-TMLE","text":"use simulated data 2015 NIEHS Mixtures Workshop developed determine new mixture methods detect ground-truth interactions built simulated data. way can simultaneously show CVtreeMLE output, interpretation validity. NIEHS Data detailed information simulated data please see: https://github.com/niehs-prime/2015-NIEHS-MIxtures-Workshop Briefly, synthetic data can considered results prospective cohort epidemiologic study. outcome cause exposures (might occur cross-sectional study). Correlations exposure variables can thought caused common sources modes exposure. nuisance variable Z can assumed potential confounder collider. 7 exposures complicated dependency structure. \\(X_3\\) \\(X_6\\) impact outcome. One issue many machine learning algorithms fail given 1 variable passed feature let’s add covariates.","code":"niehs_data <- NIEHS_data_1  head(niehs_data) %>%   kableExtra::kbl(caption = \"NIEHS Data\") %>%   kableExtra::kable_classic(full_width = FALSE, html_font = \"Cambria\") niehs_data$Z2 <- rbinom(nrow(niehs_data),   size = 1,   prob = 0.3 )  niehs_data$Z3 <- rbinom(nrow(niehs_data),   size = 1,   prob = 0.1 )"},{"path":"/articles/intro_CVtreeMLE.html","id":"run-cvtreemle","dir":"Articles","previous_headings":"","what":"Run CVtreeMLE","title":"Evaluating Causal Effects of Mixed Exposures using Data Adaptive Decision Trees and CV-TMLE","text":"","code":"ptm <- proc.time()  niehs_results <- CVtreeMLE(   data = as.data.frame(niehs_data),   w = c(\"Z\", \"Z2\", \"Z3\"),   a = c(paste(\"X\", seq(7), sep = \"\")),   y = \"Y\",   n_folds = 5,   seed = seed,   parallel_cv = TRUE,   parallel = TRUE,   family = \"continuous\",   num_cores = 8,   min_max = \"min\",   min_obs = 25 ) #> [1] \"Depth: 0 Parent mean: Inf Parent N: 400\" #> [1] \"Best split found at depth: 0 Split on: X3 at point: 0.19\" #> [1] \"Going deeper from depth: 0 with left rule: X3 <= 0.19 & \" #> [1] \"Going deeper from depth: 0 with right rule: X3 > 0.19 & \" #> [1] \"Depth: 1 Parent mean: 12.4004844250252 Parent N: 29\" #> [1] \"No best split found at depth: 1\" #> [1] \"Depth: 1 Parent mean: 12.4004844250252 Parent N: 371\" #> [1] \"No best split found at depth: 1\" #> [1] \"Depth: 0 Parent mean: Inf Parent N: 400\" #> [1] \"Best split found at depth: 0 Split on: X2 at point: 0.41\" #> [1] \"Going deeper from depth: 0 with left rule: X2 <= 0.41 & \" #> [1] \"Going deeper from depth: 0 with right rule: X2 > 0.41 & \" #> [1] \"Depth: 1 Parent mean: 12.3730729629427 Parent N: 27\" #> [1] \"No best split found at depth: 1\" #> [1] \"Depth: 1 Parent mean: 12.3730729629427 Parent N: 373\" #> [1] \"No best split found at depth: 1\" #> [1] \"Depth: 0 Parent mean: Inf Parent N: 400\" #> [1] \"Best split found at depth: 0 Split on: X2 at point: 0.4\" #> [1] \"Going deeper from depth: 0 with left rule: X2 <= 0.4 & \" #> [1] \"Going deeper from depth: 0 with right rule: X2 > 0.4 & \" #> [1] \"Depth: 1 Parent mean: 11.668194297295 Parent N: 25\" #> [1] \"No best split found at depth: 1\" #> [1] \"Depth: 1 Parent mean: 11.668194297295 Parent N: 375\" #> [1] \"No best split found at depth: 1\" #> [1] \"Depth: 0 Parent mean: Inf Parent N: 400\" #> [1] \"Best split found at depth: 0 Split on: X1 at point: 0.18\" #> [1] \"Going deeper from depth: 0 with left rule: X1 <= 0.18 & \" #> [1] \"Going deeper from depth: 0 with right rule: X1 > 0.18 & \" #> [1] \"Depth: 1 Parent mean: 11.8737320938925 Parent N: 29\" #> [1] \"No best split found at depth: 1\" #> [1] \"Depth: 1 Parent mean: 11.8737320938925 Parent N: 371\" #> [1] \"No best split found at depth: 1\" #> [1] \"Depth: 0 Parent mean: Inf Parent N: 400\" #> [1] \"Best split found at depth: 0 Split on: X2 at point: 0.41\" #> [1] \"Going deeper from depth: 0 with left rule: X2 <= 0.41 & \" #> [1] \"Going deeper from depth: 0 with right rule: X2 > 0.41 & \" #> [1] \"Depth: 1 Parent mean: 11.7150451328596 Parent N: 28\" #> [1] \"No best split found at depth: 1\" #> [1] \"Depth: 1 Parent mean: 11.7150451328596 Parent N: 372\" #> [1] \"No best split found at depth: 1\" proc.time() - ptm #>    user  system elapsed  #>   7.739   0.407 181.642"},{"path":"/articles/intro_CVtreeMLE.html","id":"mixture-results","dir":"Articles","previous_headings":"","what":"Mixture Results","title":"Evaluating Causal Effects of Mixed Exposures using Data Adaptive Decision Trees and CV-TMLE","text":"First let’s look oracle estimate. pooled CV-TMLE estimates parameter region maximizes minimizes expected outcome - different incosistencies estimates across folds. Oracle Mixture Results shows estimate pooled region minimizes expected outcome -3.77, significant. can look regions comprise oracle region: Region Specific Mixture Results shows 80% folds find region X2 20% X1, becomes consistent higher folds used. K-fold Results","code":"pooled_mixture_results <- niehs_results$`Oracle Region Results`  pooled_mixture_results %>%   kableExtra::kbl(caption = \"Oracle Mixture Results\") %>%   kableExtra::kable_classic(full_width = FALSE, html_font = \"Cambria\") region_specific_pooling <- niehs_results$`Pooled TMLE Mixture Results`  region_specific_pooling %>%   kableExtra::kbl(caption = \"Region Specific Mixture Results\") %>%   kableExtra::kable_classic(full_width = FALSE, html_font = \"Cambria\") k_fold_results <- niehs_results$`V-Specific Mix Results`  k_fold_results %>%   kableExtra::kbl(caption = \"K-fold Results\") %>%   kableExtra::kable_classic(full_width = FALSE, html_font = \"Cambria\")"},{"path":"/articles/intro_CVtreeMLE.html","id":"estimate-stability","dir":"Articles","previous_headings":"","what":"Estimate Stability","title":"Evaluating Causal Effects of Mixed Exposures using Data Adaptive Decision Trees and CV-TMLE","text":"identifying thresholds mixture space data-adaptively using training data rotate folds, CVtreeMLE give, event signal actually exists, consistent results higher n_fold values used. Thus, recommend using 10-fold CV possible consistent interpretable results. , 5-fold used simply convenience compiling testing. noted , especially marginal results, analyst chooses report results one fold, valid inference, variability thresholds estimates across folds also provided full transparency.","code":""},{"path":"/articles/intro_CVtreeMLE.html","id":"runtime-performance-guidelines","dir":"Articles","previous_headings":"","what":"Runtime Performance Guidelines","title":"Evaluating Causal Effects of Mixed Exposures using Data Adaptive Decision Trees and CV-TMLE","text":"CVtreeMLE uses ensemble machine learning obviously computationally demanding. utils_create_sls.R function creates lean yet non-parametric ensemble learners parameter. example, glm, elastic net, random forest, xgboost models created nuisance parameters decision trees various depths created decision tree fitting Super Learner. Users also welcome pass stacks learners CVtreeMLE feel default estimators insufficient given complexity data. Additionally, help computational time, CVtreeMLE uses future package sequential parallel processing. default functionality parallelize across folds (parallel_cv = TRUE). default parallelization type multi-session, expect users programming Rstudio multicore supported. Thus, user expected multiple cores use, number equal num_cores high CPU usage core data models copied core. different multicore data copied. saw , example, dataset 500 observations 7 exposures took 5 minutes 5 folds. Thus, using 10-fold CV, recommend, standard environmental epidemiology data set 500- 1000 observations, CVtreeMLE run easily modern local machine.","code":""},{"path":[]},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"David McCoy. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"McCoy D (2024). CVtreeMLE: Cross Validated Decision Trees Targeted Maximum Likelihood Estimation. R package version 0.0.0.9000.","code":"@Manual{,   title = {CVtreeMLE: Cross Validated Decision Trees with Targeted Maximum Likelihood Estimation},   author = {David McCoy},   year = {2024},   note = {R package version 0.0.0.9000}, }"},{"path":"/contributing.html","id":null,"dir":"","previous_headings":"","what":"Contributing to CVtreeMLE","title":"Contributing to CVtreeMLE","text":"love input! want make contributing project easy transparent possible, whether ’s: Reporting bug Discussing current state code Submitting fix Proposing new features Becoming maintainer","code":""},{"path":"/contributing.html","id":"we-develop-with-github","dir":"","previous_headings":"","what":"We Develop with Github","title":"Contributing to CVtreeMLE","text":"use github host code, track issues feature requests, well accept pull requests.","code":""},{"path":"/contributing.html","id":"we-use-github-flow-so-all-code-changes-happen-through-pull-requests","dir":"","previous_headings":"","what":"We Use Github Flow, So All Code Changes Happen Through Pull Requests","title":"Contributing to CVtreeMLE","text":"Pull requests best way propose changes codebase (use Github Flow). actively welcome pull requests: Fork repo create branch master. ’ve added code tested, add tests. ’ve changed APIs, update documentation. Ensure test suite passes. Make sure code lints. Issue pull request!","code":""},{"path":"/contributing.html","id":"any-contributions-you-make-will-be-under-the-mit-software-license","dir":"","previous_headings":"","what":"Any contributions you make will be under the MIT Software License","title":"Contributing to CVtreeMLE","text":"short, submit code changes, submissions understood MIT License covers project. Feel free contact maintainers ’s concern.","code":""},{"path":"/contributing.html","id":"report-bugs-using-githubs-issues","dir":"","previous_headings":"","what":"Report bugs using Github’s issues","title":"Contributing to CVtreeMLE","text":"use GitHub issues track public bugs. Report bug opening new issue; ’s easy!","code":""},{"path":"/contributing.html","id":"write-bug-reports-with-detail-background-and-sample-code","dir":"","previous_headings":"","what":"Write bug reports with detail, background, and sample code","title":"Contributing to CVtreeMLE","text":"example bug report written, think ’s bad model. ’s another example Craig Hockenberry, app developer greatly respect. Great Bug Reports tend : quick summary /background specific! Give sample code can. stackoverflow question includes sample code anyone base R setup can run reproduce seeing expected happen actually happens Notes (possibly including think might happening, stuff tried didn’t work) People love thorough bug reports. ’m even kidding.","code":""},{"path":"/contributing.html","id":"use-a-consistent-coding-style","dir":"","previous_headings":"","what":"Use a Consistent Coding Style","title":"Contributing to CVtreeMLE","text":"’m borrowing Facebook’s Guidelines 2 spaces indentation rather tabs can try running npm run lint style unification","code":""},{"path":"/contributing.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Contributing to CVtreeMLE","text":"contributing, agree contributions licensed MIT License.","code":""},{"path":"/contributing.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Contributing to CVtreeMLE","text":"document adapted open-source contribution guidelines Facebook’s Draft","code":""},{"path":"/index.html","id":"cvtreemle-img-srcmanfigurescvtreemle_stickerpng-height300-alignright","dir":"","previous_headings":"","what":"Cross Validated Decision Trees with Targeted Maximum Likelihood\n    Estimation","title":"Cross Validated Decision Trees with Targeted Maximum Likelihood\n    Estimation","text":"Discovery Critical Thresholds Mixed Exposures Estimation Policy Intervention Effects using Targeted Learning Author: David McCoy","code":""},{"path":"/index.html","id":"what-is-cvtreemle","dir":"","previous_headings":"","what":"What is CVtreeMLE?","title":"Cross Validated Decision Trees with Targeted Maximum Likelihood\n    Estimation","text":"People often encounter multiple simultaneous exposures (e.g. several drugs pollutants). Policymakers interested setting safe limits, interdictions, recommended dosage combinations based combination thresholds, one per exposure. Setting thresholds difficult relevant interactions exposures must accounted . Previous statistical methods used parametric estimators directly address question superadditive subadditive effects mixture, rely unrealistic assumptions, result threshold based statistical quantity directly relevant policy regulators. present estimator ) identifies thresholds minimize/maximize expected outcome marginalized covariates exposures; b) unbiasedly efficiently estimates policy intervention compares expected outcome everyone forced safe levels compared observed outcome observed exposure distribution. done combining custom g-computation tree-based search algorithm targeted maximum likelihood estimator using cross-validation. package takes mixed exposure, covariates, outcome, super learner stacks learners determined (default used), number folds, minimum observations region, desired region minimizer maximizer parallelization parameters. output k-fold specific results region found fold valid inference, pooled estimate overall oracle parameter across folds pooled exposure sets region inconsistency across folds.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Cross Validated Decision Trees with Targeted Maximum Likelihood\n    Estimation","text":"Note: CVtreeMLE package (currently) depends sl3 allows ensemble machine learning used nuisance parameter estimation sl3 CRAN CVtreeMLE package available CRAN must downloaded . many dependencies CVtreeMLE ’s easier break installation various packages ensure proper installation. CVtreeMLE uses sl3 package build ensemble machine learners nuisance parameter. install development branch, first download two packages sl3 Now install sl3 devel: Make sure sl3 installs correctly install CVtreeMLE CVtreeMLE miscellaneous dependencies used examples well plotting functions.","code":"install.packages(c(\"ranger\", \"arm\", \"xgboost\", \"nnls\")) remotes::install_github(\"tlverse/sl3@devel\") remotes::install_github(\"blind-contours/CVtreeMLE@main\") install.packages(c(\"kableExtra\", \"hrbrthemes\", \"viridis\"))"},{"path":"/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Cross Validated Decision Trees with Targeted Maximum Likelihood\n    Estimation","text":"First load package packages needed illustrate CVtreeMLE may used find esitmate region , intervened lead biggest reduction outcome use simulated data described paper: arXiv:2302.07976 Briefly, 2 discrete exposures created based multinomial regression baseline covariates. create outcome main effect squared interactions. One region minimum expected outcome, exposures equal 1.","code":"library(CVtreeMLE) library(sl3) library(pre) library(partykit) library(kableExtra) library(ggplot2) library(here) source(here(\"sandbox\", \"simulate_2d_data.R\"))  set.seed(429153) n <- 400 exposure_grid <- expand.grid(seq(5), seq(5)) labels <- apply(exposure_grid, 1, paste, collapse = \" \") exposure_grid <- cbind.data.frame(exposure_grid, labels)  # beta matrix c_matrix <- matrix(c(0.1,0.7,0.8,0.9),                    ncol  = 2,                    nrow = 2)  # Generate simulated data ----------------- P_0_sim <- gen_covariates(n) %>% # gen covariates   gen_multinom(exposure_grid = exposure_grid) %>% # assign obs to exposure cube   assign_outcomes(exposure_grid = exposure_grid,                   c_matrix = c_matrix) #> Warning: `rbernoulli()` was deprecated in purrr 1.0.0. #> This warning is displayed once every 8 hours. #> Call `lifecycle::last_lifecycle_warnings()` to see where this warning was #> generated.  intro_data <- P_0_sim$data"},{"path":"/index.html","id":"run-cvtreemle","dir":"","previous_headings":"","what":"Run CVtreeMLE","title":"Cross Validated Decision Trees with Targeted Maximum Likelihood\n    Estimation","text":"now pass simulated data variable names node O = W,,Y CVtreeMLE function. can look pooled TMLE results model. Let’s see CVtreeMLE identified thresholds minimizing region: Oracle Results region, region 1 = 1 region 2 = 1. found folds variability oracle estimate. -0.2 indicates make policy forced everyone exposure levels 1 exposures expected outcome 0.2 less current average. can also look v-fold specific results: see fold specific estimates used pooled TMLE output saw earlier. Additional details features given vignette.","code":"ptm <- proc.time()  sim_results <- CVtreeMLE(   data = intro_data,   w = c(\"age\", \"sex\", \"bmi\"),   a = c(\"region1\", \"region2\"),   y = \"outcome_obs\",   n_folds = 5,   parallel_cv = TRUE,   seed = 2333,   parallel_type = \"multi_session\",   family = \"continuous\",   num_cores = 2 ) #> [1] \"Depth: 0 Parent mean: Inf Parent N: 320\" #> [1] \"Best split found at depth: 0 Split on: region2 at point: 1\" #> [1] \"Going deeper from depth: 0 with left rule: region2 <= 1 & \" #> [1] \"Going deeper from depth: 0 with right rule: region2 > 1 & \" #> [1] \"Depth: 1 Parent mean: 16.2745921683027 Parent N: 65\" #> [1] \"Best split found at depth: 1 Split on: region1 at point: 3\" #> [1] \"Going deeper from depth: 1 with left rule: region2 <= 1 & region1 <= 3 & \" #> [1] \"Going deeper from depth: 1 with right rule: region2 <= 1 & region1 > 3 & \" #> [1] \"Depth: 2 Parent mean: 12.6368174660957 Parent N: 28\" #> [1] \"No best split found at depth: 2\" #> [1] \"Depth: 2 Parent mean: 12.6368174660957 Parent N: 37\" #> [1] \"No best split found at depth: 2\" #> [1] \"Depth: 1 Parent mean: 16.2745921683027 Parent N: 255\" #> [1] \"No best split found at depth: 1\" #> [1] \"Depth: 0 Parent mean: Inf Parent N: 320\" #> [1] \"Best split found at depth: 0 Split on: region2 at point: 1\" #> [1] \"Going deeper from depth: 0 with left rule: region2 <= 1 & \" #> [1] \"Going deeper from depth: 0 with right rule: region2 > 1 & \" #> [1] \"Depth: 1 Parent mean: 16.6119824135153 Parent N: 61\" #> [1] \"No best split found at depth: 1\" #> [1] \"Depth: 1 Parent mean: 16.6119824135153 Parent N: 259\" #> [1] \"No best split found at depth: 1\" #> [1] \"Depth: 0 Parent mean: Inf Parent N: 320\" #> [1] \"Best split found at depth: 0 Split on: region2 at point: 1\" #> [1] \"Going deeper from depth: 0 with left rule: region2 <= 1 & \" #> [1] \"Going deeper from depth: 0 with right rule: region2 > 1 & \" #> [1] \"Depth: 1 Parent mean: 16.9582644829873 Parent N: 63\" #> [1] \"No best split found at depth: 1\" #> [1] \"Depth: 1 Parent mean: 16.9582644829873 Parent N: 257\" #> [1] \"No best split found at depth: 1\" #> [1] \"Depth: 0 Parent mean: Inf Parent N: 320\" #> [1] \"Best split found at depth: 0 Split on: region2 at point: 1\" #> [1] \"Going deeper from depth: 0 with left rule: region2 <= 1 & \" #> [1] \"Going deeper from depth: 0 with right rule: region2 > 1 & \" #> [1] \"Depth: 1 Parent mean: 16.3762713516552 Parent N: 66\" #> [1] \"Best split found at depth: 1 Split on: region1 at point: 3\" #> [1] \"Going deeper from depth: 1 with left rule: region2 <= 1 & region1 <= 3 & \" #> [1] \"Going deeper from depth: 1 with right rule: region2 <= 1 & region1 > 3 & \" #> [1] \"Depth: 2 Parent mean: 12.9263815293611 Parent N: 27\" #> [1] \"No best split found at depth: 2\" #> [1] \"Depth: 2 Parent mean: 12.9263815293611 Parent N: 39\" #> [1] \"No best split found at depth: 2\" #> [1] \"Depth: 1 Parent mean: 16.3762713516552 Parent N: 254\" #> [1] \"No best split found at depth: 1\" #> [1] \"Depth: 0 Parent mean: Inf Parent N: 320\" #> [1] \"Best split found at depth: 0 Split on: region2 at point: 1\" #> [1] \"Going deeper from depth: 0 with left rule: region2 <= 1 & \" #> [1] \"Going deeper from depth: 0 with right rule: region2 > 1 & \" #> [1] \"Depth: 1 Parent mean: 16.2722177201016 Parent N: 57\" #> [1] \"Best split found at depth: 1 Split on: region1 at point: 3\" #> [1] \"Going deeper from depth: 1 with left rule: region2 <= 1 & region1 <= 3 & \" #> [1] \"Going deeper from depth: 1 with right rule: region2 <= 1 & region1 > 3 & \" #> [1] \"Depth: 2 Parent mean: 12.5806656759671 Parent N: 25\" #> [1] \"No best split found at depth: 2\" #> [1] \"Depth: 2 Parent mean: 12.5806656759671 Parent N: 32\" #> [1] \"No best split found at depth: 2\" #> [1] \"Depth: 1 Parent mean: 16.2722177201016 Parent N: 263\" #> [1] \"No best split found at depth: 1\"  proc.time() - ptm #>    user  system elapsed  #>   4.785   0.604  82.810 mixture_results <- sim_results$`Pooled TMLE Mixture Results` mixture_results %>%   kbl(caption = \"Oracle Results\") %>%   kable_classic(full_width = FALSE, html_font = \"Cambria\") sim_results$`V-Specific Mix Results` #>       are    se lower_ci upper_ci    p_val p_val_adj   rmse #> 1  -0.920 0.313   -1.535   -0.306 0.003322  0.016611  0.236 #> 2 -20.565 5.532  -31.407   -9.723 0.000201  0.001006 11.648 #> 3 -18.192 5.193  -28.371   -8.013 0.000460  0.002302 11.067 #> 4  -0.388 0.327   -1.029    0.252 0.234842  1.000000  0.521 #> 5  -2.096 0.345   -2.772   -1.419 0.000000  0.000000  0.203 #>                      mix_rule fold       variables #> 1 region2 <= 1 & region1 <= 3    1 region2-region1 #> 2                region2 <= 1    2         region2 #> 3                region2 <= 1    3         region2 #> 4 region2 <= 1 & region1 <= 3    4 region2-region1 #> 5 region2 <= 1 & region1 <= 3    5 region2-region1"},{"path":"/index.html","id":"issues","dir":"","previous_headings":"","what":"Issues","title":"Cross Validated Decision Trees with Targeted Maximum Likelihood\n    Estimation","text":"encounter bugs specific feature requests, please file issue. details filing issues provided contribution guidelines.","code":""},{"path":"/index.html","id":"contributions","dir":"","previous_headings":"","what":"Contributions","title":"Cross Validated Decision Trees with Targeted Maximum Likelihood\n    Estimation","text":"Contributions welcome. Interested contributors consult contribution guidelines prior submitting pull request.","code":""},{"path":"/index.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Cross Validated Decision Trees with Targeted Maximum Likelihood\n    Estimation","text":"using CVtreeMLE R package, please cite following: (article?){McCoy2023, doi = {10.21105/joss.04181}, url = {https://doi.org/10.21105/joss.04181}, year = {2023}, publisher = {Open Journal}, volume = {8}, number = {82}, pages = {4181}, author = {David McCoy Alan Hubbard Mark Van der Laan}, title = {CVtreeMLE: Efficient Estimation Mixed Exposures using Data Adaptive Decision Trees Cross-Validated Targeted Maximum Likelihood Estimation R}, journal = {Journal Open Source Software} }","code":""},{"path":"/index.html","id":"related","dir":"","previous_headings":"","what":"Related","title":"Cross Validated Decision Trees with Targeted Maximum Likelihood\n    Estimation","text":"R/sl3 - R package providing implementation Super Learner ensemble machine learning algorithms. R/SuperLearner - Legacy R package providing implementation Super Learner ensemble machine learning algorithms.","code":""},{"path":"/index.html","id":"funding","dir":"","previous_headings":"","what":"Funding","title":"Cross Validated Decision Trees with Targeted Maximum Likelihood\n    Estimation","text":"development software supported part grants NIH-funded Biomedical Big Data Training Program UC Berkeley biomedical big data fellow.","code":""},{"path":"/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Cross Validated Decision Trees with Targeted Maximum Likelihood\n    Estimation","text":"© 2017-2024 David B. McCoy contents repository distributed MIT license. See details:","code":"MIT License Copyright (c) 2017-2024 David B. McCoy Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."},{"path":[]},{"path":"/reference/CVtreeMLE.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit ensemble decision trees to a vector of exposures and use targeted\nmaximum likelihood estimation to determine the average treatment effect\nin each leaf of best fitting tree — CVtreeMLE","title":"Fit ensemble decision trees to a vector of exposures and use targeted\nmaximum likelihood estimation to determine the average treatment effect\nin each leaf of best fitting tree — CVtreeMLE","text":"Fit ensemble decision trees mixed exposure controlling covariates using iterative backfitting two Super Learners. partitioning nodes identified, use partitions rule-based exposure. CV-TMLE framework used create training estimation samples. Trees fit training average treatment effect (ATE) rule-based exposure estimated validation folds. type mixed exposure (continuous, binary, multinomial) accepted. ATE multiple mixture components (interactions) given well marginal effects data-adaptively identified.","code":""},{"path":"/reference/CVtreeMLE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit ensemble decision trees to a vector of exposures and use targeted\nmaximum likelihood estimation to determine the average treatment effect\nin each leaf of best fitting tree — CVtreeMLE","text":"","code":"CVtreeMLE(   w,   a,   y,   data,   w_stack = NULL,   aw_stack = NULL,   a_stack = NULL,   n_folds,   seed = 6442,   family,   parallel = TRUE,   parallel_cv = TRUE,   parallel_type = \"multi_session\",   num_cores = 2,   h_aw_trunc_lvl = 50,   pooled_rule_type = \"average\",   min_max = \"min\",   region = NULL,   min_obs = 25 )"},{"path":"/reference/CVtreeMLE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit ensemble decision trees to a vector of exposures and use targeted\nmaximum likelihood estimation to determine the average treatment effect\nin each leaf of best fitting tree — CVtreeMLE","text":"w character vector indicating variables data use baseline covariates. character vector indicating variables data use exposures. y character indicating variable data use outcome. data Data frame (W,,Y) variables interest. w_stack Stack estimators used Super Learner iterative backfitting Y|W, SL3 stack. provided, utils_create_sls used create default estimators used ensemble. aw_stack Stack estimators used Super Learner Q g mechanisms. provided, utils_create_sls used create default estimators used ensemble. a_stack Stack estimators used Super Learner iterative backfitting Y|, SL3 object. provided, utils_create_sls used create default decision tree estimators used ensemble. n_folds Number cross-validation folds. seed Pass seed number consistency results. provided default seed generated. family Family ('binomial' 'continuous'). parallel Use parallel processing backend registered; enabled default. parallel_cv Use parallel processing CV procedure vs. parallel processing Super Learner model fitting parallel_type default multi_session, parallel true type parallelization multi_session multicore num_cores using parallel, number cores parallelize h_aw_trunc_lvl Level truncate clever covariate control variance, default 10. pooled_rule_type \"average\" \"union\" construct rule across folds. average take average cutpoints returns average rule lower upper bounds cutpoint. union rule creates new rule space contains rules found across fold therefore conservative. fit_marginals TRUE/FALSE whether find cut-points ATEs data-adaptive level dose-response relationship individual exposure. Default FALSE. which_marginals fit marginals TRUE, marginals CVtreeMLE identify partition nodes ? Takes list exposures. direction Positive negative, whether select tree maximum (positive) coefficient attached ensemble minimum (negative). positive, positive ATEs given, negative, negative ATEs given. verbose true, message printed indicating process started CVtreeMLE. iterative backfitting procedure iteration fold along difference model fit rules determined printed. iterative backfitting procedures table rules determined fold printed.","code":""},{"path":"/reference/CVtreeMLE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit ensemble decision trees to a vector of exposures and use targeted\nmaximum likelihood estimation to determine the average treatment effect\nin each leaf of best fitting tree — CVtreeMLE","text":"Object class CVtreeMLE, containing list table results : marginal ATEs, mixture ATEs, RMSE marginal model fits, RMSE mixture model fits, marginal rules, mixture rules. Model RMSEs: Root mean square error marginal interaction models iterative backfitting procedure Pooled TMLE Marginal Results: Data frame pooled TMLE Marginal Results: Pooled ATE results using TMLE thresholds identified mixture component found V-Specific Marg Results: list v-fold marginal results. grouped variable direction ATE. Pooled TMLE Mixture Results: Data frame pooled TMLE Mixture Results V-Specific Mix Results: list v-fold mixture results. grouped variable direction ATE. Pooled Marginal Refs: data frame reference categories determined marginal results. Marginal Rules: data frame includes marginal rules details related fold found RMSE Mixture Rules: data frame includes mixture rules details related fold found RMSE","code":""},{"path":"/reference/CVtreeMLE.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit ensemble decision trees to a vector of exposures and use targeted\nmaximum likelihood estimation to determine the average treatment effect\nin each leaf of best fitting tree — CVtreeMLE","text":"function performs following functions. Imputes missing values mean creates dummy indicator variables imputed variables. Separate covariates factors continuous (ordered). Create variable indicates fold number assigned observation. Fit iterative backfitting algorithm onto mixed exposure applies ensemble decision trees mixed exposure unrestricted Super Learner covariates. Algorithms fit, offset compliment virtually difference model fits. Extract partition nodes found mixture. done training fold data. Fit iterative backfitting algorithm onto individual mixture component applies ensemble decision trees mixed exposure unrestricted Super Learner covariates. Algorithms fit, offset compliment virtually difference model fits. Extract partition nodes found mixture. done training fold data. Estimate nuisance parameters (Q g estimates) mixture interaction rule Estimate nuisance parameters (Q g estimates) marginal rules Estimate Q outcome mechanism marginal rules later user input targeted ATE different marginal combinations based data-adaptively identified thresholds. Use mixture rules data TMLE fluctuation step target ATE given rule across folds. Calculate proportion folds rule found. Use marginal rules data TMLE fluctuation step target ATE given rule across folds. Calculate proportion folds rule found. Calculate V-fold specific TMLE estimates rules. mixture rules, calculate union rule rule covers observations across folds respective variable set rule. marginal rules, calculate union rule rule covers observations across folds respective variable set rule.","code":""},{"path":"/reference/CVtreeMLE.html","id":"authors","dir":"Reference","previous_headings":"","what":"Authors","title":"Fit ensemble decision trees to a vector of exposures and use targeted\nmaximum likelihood estimation to determine the average treatment effect\nin each leaf of best fitting tree — CVtreeMLE","text":"David McCoy, University California, Berkeley","code":""},{"path":"/reference/CVtreeMLE.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fit ensemble decision trees to a vector of exposures and use targeted\nmaximum likelihood estimation to determine the average treatment effect\nin each leaf of best fitting tree — CVtreeMLE","text":"Benjamini, Y., & Hochberg, Y. (1995). Controlling false discovery rate: practical powerful approach multiple testing. Journal royal statistical society. Series B (Methodological), 289-300. Gruber, S., & van der Laan, M. J. (2012). tmle: R Package Targeted Maximum Likelihood Estimation. Journal Statistical Software, 51(i13). Hubbard, . E., Kherad-Pajouh, S., & van der Laan, M. J. (2016). Statistical Inference Data Adaptive Target Parameters. international journal biostatistics, 12(1), 3-19. Hubbard, ., Munoz, . D., Decker, ., Holcomb, J. B., Schreiber, M. ., Bulger, E. M., ... & Rahbar, M. H. (2013). Time-Dependent Prediction Evaluation Variable Importance Using SuperLearning High Dimensional Clinical Data. journal trauma acute care surgery, 75(1 0 1), S53. Hubbard, . E., & van der Laan, M. J. (2016). Mining inference: data-adaptive target parameters (pp. 439-452). P. Buhlmann et al. (Ed.), Handbook Big Data. CRC Press, Taylor & Francis Group, LLC: Boca Raton, FL. van der Laan, M. J. (2006). Statistical inference variable importance. International Journal Biostatistics, 2(1). van der Laan, M. J., & Pollard, K. S. (2003). new algorithm hybrid hierarchical clustering visualization bootstrap. Journal Statistical Planning Inference, 117(2), 275-303. van der Laan, M. J., Polley, E. C., & Hubbard, . E. (2007). Super learner. Statistical applications genetics molecular biology, 6(1). van der Laan, M. J., & Rose, S. (2011). Targeted learning: causal inference observational experimental data. Springer Science & Business Media.","code":""},{"path":"/reference/CVtreeMLE.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit ensemble decision trees to a vector of exposures and use targeted\nmaximum likelihood estimation to determine the average treatment effect\nin each leaf of best fitting tree — CVtreeMLE","text":"","code":"n <- 800 p <- 4 x <- matrix(rnorm(n * p), n, p) colnames(x) <- c(\"A1\", \"A2\", \"W1\", \"W2\") y_prob <- plogis(3 * sin(x[, 1]) + sin(x[, 2]), sin(x[, 4])) Y <- rbinom(n = n, size = 1, prob = y_prob) data <- as.data.frame(cbind(x, Y))  CVtreeMLE_fit <- CVtreeMLE(   data = data,   w = c(\"W1\", \"W2\"),   a = c(\"A1\", \"A2\"),   y = \"Y\",   family = \"binomial\",   parallel = FALSE,   n_folds = 2 ) #> [1] \"Depth: 0 Parent mean: Inf Parent N: 399\" #> [1] \"Best split found at depth: 0 Split on: A1 at point: -0.77\" #> [1] \"Going deeper from depth: 0 with left rule: A1 <= -0.77 & \" #> [1] \"Going deeper from depth: 0 with right rule: A1 > -0.77 & \" #> [1] \"Depth: 1 Parent mean: 0.0912095694473117 Parent N: 85\" #> [1] \"Best split found at depth: 1 Split on: A1 at point: -1.31\" #> [1] \"Going deeper from depth: 1 with left rule: A1 <= -0.77 & A1 <= -1.31 & \" #> [1] \"Going deeper from depth: 1 with right rule: A1 <= -0.77 & A1 > -1.31 & \" #> [1] \"Depth: 2 Parent mean: 0.0415808701680934 Parent N: 35\" #> [1] \"No best split found at depth: 2\" #> [1] \"Depth: 2 Parent mean: 0.0415808701680934 Parent N: 50\" #> [1] \"No best split found at depth: 2\" #> [1] \"Depth: 1 Parent mean: 0.0912095694473117 Parent N: 314\" #> [1] \"No best split found at depth: 1\" #> [1] \"Depth: 0 Parent mean: Inf Parent N: 401\" #> [1] \"Best split found at depth: 0 Split on: A1 at point: -1.08\" #> [1] \"Going deeper from depth: 0 with left rule: A1 <= -1.08 & \" #> [1] \"Going deeper from depth: 0 with right rule: A1 > -1.08 & \" #> [1] \"Depth: 1 Parent mean: 0.098421841521049 Parent N: 55\" #> [1] \"Best split found at depth: 1 Split on: A2 at point: -0.09\" #> [1] \"Going deeper from depth: 1 with left rule: A1 <= -1.08 & A2 <= -0.09 & \" #> [1] \"Going deeper from depth: 1 with right rule: A1 <= -1.08 & A2 > -0.09 & \" #> [1] \"Depth: 2 Parent mean: 0.0544922938192713 Parent N: 28\" #> [1] \"No best split found at depth: 2\" #> [1] \"Depth: 2 Parent mean: 0.0544922938192713 Parent N: 27\" #> [1] \"No best split found at depth: 2\" #> [1] \"Depth: 1 Parent mean: 0.098421841521049 Parent N: 346\" #> [1] \"No best split found at depth: 1\" #>  #> Attaching package: ‘sl3’ #> The following object is masked from ‘package:ranger’: #>  #>     importance"},{"path":"/reference/NHANES_eurocim.html","id":null,"dir":"Reference","previous_headings":"","what":"NHANES 2001-2002, POP Exposure on Telomere Length — NHANES_eurocim","title":"NHANES 2001-2002, POP Exposure on Telomere Length — NHANES_eurocim","text":"subset data NHANES reproduce analysis used Mitro et. al., Gibson et. al.","code":""},{"path":"/reference/NHANES_eurocim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NHANES 2001-2002, POP Exposure on Telomere Length — NHANES_eurocim","text":"","code":"NHANES_eurocim"},{"path":[]},{"path":"/reference/NHANES_eurocim.html","id":"nhanes-eurocim","dir":"Reference","previous_headings":"","what":"NHANES_eurocim","title":"NHANES 2001-2002, POP Exposure on Telomere Length — NHANES_eurocim","text":"data frame 1,330 rows 33 columns:","code":""},{"path":"/reference/NIEHS_data_1.html","id":null,"dir":"Reference","previous_headings":"","what":"Data 1 from the NIEHS mixtures workshop — NIEHS_data_1","title":"Data 1 from the NIEHS mixtures workshop — NIEHS_data_1","text":"dataset containing simulated mixture data NIEHS","code":""},{"path":"/reference/NIEHS_data_1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Data 1 from the NIEHS mixtures workshop — NIEHS_data_1","text":"","code":"NIEHS_data_1"},{"path":"/reference/NIEHS_data_1.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Data 1 from the NIEHS mixtures workshop — NIEHS_data_1","text":"data frame 500 rows 9 variables:","code":""},{"path":"/reference/NIEHS_data_1.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Data 1 from the NIEHS mixtures workshop — NIEHS_data_1","text":"https://github.com/niehs-prime/2015-NIEHS-MIxtures-Workshop","code":""},{"path":"/reference/average_mixture_rules.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the average rule. This is the rule that is the average\nacross thresholds in folds and gives the lower and upper bounds — average_mixture_rules","title":"Estimate the average rule. This is the rule that is the average\nacross thresholds in folds and gives the lower and upper bounds — average_mixture_rules","text":"function takes list rules grouped variable sets. rules different variable sets may slightly different across folds make average rule variable set. entails creating new rule average cutpoints:","code":""},{"path":"/reference/average_mixture_rules.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the average rule. This is the rule that is the average\nacross thresholds in folds and gives the lower and upper bounds — average_mixture_rules","text":"","code":"average_mixture_rules(   group_list,   data = data,   mix_comps = mix_comps,   n_folds,   mixture_results )"},{"path":"/reference/average_mixture_rules.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the average rule. This is the rule that is the average\nacross thresholds in folds and gives the lower and upper bounds — average_mixture_rules","text":"group_list List dataframes grouped rules variable sets data Full data mix_comps Mixture components n_folds Number folds used cross-validation mixture_results data frame results found mixture rules no_mixture_rules TRUE/FALSE mixture rule found","code":""},{"path":"/reference/average_mixture_rules.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the average rule. This is the rule that is the average\nacross thresholds in folds and gives the lower and upper bounds — average_mixture_rules","text":"Rules object. TODO: add detail . Data frame mixture results including union rule proportion found across folds","code":""},{"path":"/reference/bound_precision.html","id":null,"dir":"Reference","previous_headings":"","what":"Bound Precision — bound_precision","title":"Bound Precision — bound_precision","text":"Bound Precision","code":""},{"path":"/reference/bound_precision.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bound Precision — bound_precision","text":"","code":"bound_precision(vals)"},{"path":"/reference/bound_precision.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bound Precision — bound_precision","text":"vals numeric vector values bounded within arbitrary machine precision. common use functionality avoid indeterminate non-finite values application stats::qlogis.","code":""},{"path":"/reference/bound_precision.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bound Precision — bound_precision","text":"numeric vector length vals, returned values bounded machine precision. intended avoid numerical instability issues.","code":""},{"path":"/reference/bound_precision.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bound Precision — bound_precision","text":"Bound values unit interval machine precision order avoid numerical instability issues downstream computation.","code":""},{"path":"/reference/bound_propensity.html","id":null,"dir":"Reference","previous_headings":"","what":"Bound Generalized Propensity Score — bound_propensity","title":"Bound Generalized Propensity Score — bound_propensity","text":"Bound Generalized Propensity Score","code":""},{"path":"/reference/bound_propensity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bound Generalized Propensity Score — bound_propensity","text":"","code":"bound_propensity(vals)"},{"path":"/reference/bound_propensity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bound Generalized Propensity Score — bound_propensity","text":"vals numeric vector propensity score estimate values. Note , parameter, propensity score (conditional) density bounded .","code":""},{"path":"/reference/bound_propensity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bound Generalized Propensity Score — bound_propensity","text":"numeric vector length vals, returned values bounded minimum lower 1/n, sample size n.","code":""},{"path":"/reference/bound_propensity.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Bound Generalized Propensity Score — bound_propensity","text":"Bound estimated values generalized propensity score (conditional density) avoid numerical instability issues arising practical violations assumption positivity.","code":""},{"path":"/reference/calc_ATE_estimates.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the ATE and variance estimates — calc_ate_estimates","title":"Calculate the ATE and variance estimates — calc_ate_estimates","text":"Calculate ATE variance estimates","code":""},{"path":"/reference/calc_ATE_estimates.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the ATE and variance estimates — calc_ate_estimates","text":"","code":"calc_ate_estimates(data, ate_var, y, p_adjust_n, v_fold = FALSE, naive = FALSE)"},{"path":"/reference/calc_ATE_estimates.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the ATE and variance estimates — calc_ate_estimates","text":"data Data frame includes treatement/exposure ate_var Variable ATE assigned data y Variable name data raw outcome p_adjust_n Number repeated measures adjust p-value v_fold TRUE/FALSE whether calculate v-fold specific ATE estimates","code":""},{"path":"/reference/calc_ATE_estimates.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the ATE and variance estimates — calc_ate_estimates","text":"numeric vector length vals, returned values bounded machine precision. intended avoid numerical instability issues.","code":""},{"path":"/reference/calc_ATE_estimates.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate the ATE and variance estimates — calc_ate_estimates","text":"Calculates average treatment effect variance estimates influence curve across folds","code":""},{"path":"/reference/calc_additive_ate.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate mixture rules found during the rpart decision tree process — calc_additive_ate","title":"Evaluate mixture rules found during the rpart decision tree process — calc_additive_ate","text":"Evaluate mixture rules found rpart decision tree process","code":""},{"path":"/reference/calc_additive_ate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate mixture rules found during the rpart decision tree process — calc_additive_ate","text":"","code":"calc_additive_ate(additive_data, Y, n_folds)"},{"path":"/reference/calc_additive_ate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate mixture rules found during the rpart decision tree process — calc_additive_ate","text":"additive_data Data cumulative exposure across folds fold specific set rules Y Character indicating Y interest n_folds Number folds used cross-validation","code":""},{"path":"/reference/calc_additive_ate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate mixture rules found during the rpart decision tree process — calc_additive_ate","text":"Rules object. TODO: add detail .","code":""},{"path":"/reference/calc_clever_covariate.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the Clever Covariate for the TMLE step of the ATE — calc_clever_covariate","title":"Calculate the Clever Covariate for the TMLE step of the ATE — calc_clever_covariate","text":"Calculate Clever Covariate TMLE step ATE","code":""},{"path":"/reference/calc_clever_covariate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the Clever Covariate for the TMLE step of the ATE — calc_clever_covariate","text":"","code":"calc_clever_covariate(ghat_1_w, data, exposure, h_aw_trunc_lvl, type = \"reg\")"},{"path":"/reference/calc_clever_covariate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the Clever Covariate for the TMLE step of the ATE — calc_clever_covariate","text":"ghat_1_w Numeric vector values unit interval represent predicted probabilities treated/exposed. data Dataframe includes treatement/exposure exposure Variable name data clever covariate calculated h_aw_trunc_lvl Truncation level clever covariate type Type clever covariate calculate, reg standard difference inverse weightings, mod used additive ATE","code":""},{"path":"/reference/calc_clever_covariate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the Clever Covariate for the TMLE step of the ATE — calc_clever_covariate","text":"numeric vector length vals, returned values bounded machine precision. intended avoid numerical instability issues.","code":""},{"path":"/reference/calc_clever_covariate.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate the Clever Covariate for the TMLE step of the ATE — calc_clever_covariate","text":"Calculates clever covariate difference inverse propensity scores treatment used TMLE update step","code":""},{"path":"/reference/calc_marginal_ate.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the ATE for each rule found for individual mixture\ncomponents. — calc_marginal_ate","title":"Calculate the ATE for each rule found for individual mixture\ncomponents. — calc_marginal_ate","text":"Aggregate marginal rules mixture variable found across folds. rule extract relevant nuisance parameter data calculated folds. Given validation data estimates across folds, tree TMLE update step target average treatment effect. Update initial counterfactuals, calculate influence curve using influence curve calculate variance estimates p-values.","code":""},{"path":"/reference/calc_marginal_ate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the ATE for each rule found for individual mixture\ncomponents. — calc_marginal_ate","text":"","code":"calc_marginal_ate(marginal_data, mix_comps, marginal_rules, y, n_folds)"},{"path":"/reference/calc_marginal_ate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the ATE for each rule found for individual mixture\ncomponents. — calc_marginal_ate","text":"marginal_data List dataframes nuisance parameter data mixture mix_comps Vector characters indicating mixture components marginal_rules List dataframes rules found across folds y Vector indicating Y n_folds Number folds used cross-validation","code":""},{"path":"/reference/calc_marginal_ate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the ATE for each rule found for individual mixture\ncomponents. — calc_marginal_ate","text":"list marginal results including: ' marginal_results: data frame data adpatively determined mixture component thresholds rows ATE, variance, RMSE estimates columns. data: list data frames mixture component threshold evaluated exposure, baseline covariates, outcome, nuisance parameter estimates, marginal ATE influence curve.","code":""},{"path":"/reference/calc_marginal_rule_RMSEs.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the mean RMSE in each marginal group — calc_marginal_rule_rmses","title":"Calculate the mean RMSE in each marginal group — calc_marginal_rule_rmses","text":"Calculate mean RMSE marginal group","code":""},{"path":"/reference/calc_marginal_rule_RMSEs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the mean RMSE in each marginal group — calc_marginal_rule_rmses","text":"","code":"calc_marginal_rule_rmses(data)"},{"path":"/reference/calc_marginal_rule_RMSEs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the mean RMSE in each marginal group — calc_marginal_rule_rmses","text":"data Input data","code":""},{"path":"/reference/calc_mixture_rule_RMSEs.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the mean RMSE in each interaction group — calc_mixture_rule_rmses","title":"Calculate the mean RMSE in each interaction group — calc_mixture_rule_rmses","text":"Calculate mean RMSE interaction group","code":""},{"path":"/reference/calc_mixture_rule_RMSEs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the mean RMSE in each interaction group — calc_mixture_rule_rmses","text":"","code":"calc_mixture_rule_rmses(data)"},{"path":"/reference/calc_mixture_rule_RMSEs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the mean RMSE in each interaction group — calc_mixture_rule_rmses","text":"data Input data","code":""},{"path":"/reference/calc_mixtures_ate.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the ATE for each mixture rule — calc_mixtures_ate","title":"Calculate the ATE for each mixture rule — calc_mixtures_ate","text":"Aggregate mixture rules found across folds variables. rule extract relevant nuisance parameter data calculated folds. Given validation data estimates across folds, tree TMLE update step target average treatment effect. Update initial counterfactuals, calculate influence curve using influence curve calculate variance estimates p-values.","code":""},{"path":"/reference/calc_mixtures_ate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the ATE for each mixture rule — calc_mixtures_ate","text":"","code":"calc_mixtures_ate(input_mix_rules, input_mix_data, y, n_folds)"},{"path":"/reference/calc_mixtures_ate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the ATE for each mixture rule — calc_mixtures_ate","text":"input_mix_rules List dataframes rules found mixture across folds input_mix_data Nuisance parameter data mixture rules found y Outcome variable across folds n_folds Number folds used cross-validation no_mixture_rules TRUE/FALSE whether mixture rules found across folds","code":""},{"path":"/reference/calc_mixtures_ate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the ATE for each mixture rule — calc_mixtures_ate","text":"list mixture analysis results includes: results: data frame variable threshold combinations rows ATE, variance consistency estimates columns. group_list: list rule combinations found ensemble decision tree model grouped variable sets rules directions coefficient linear model. Also provided fold rule found RMSE model used rule. mixture_data_list: list data frames houses data mixture rule evaluated exposure, baseline covariates, outcome, nuisance parameter estimates respective rule.","code":""},{"path":"/reference/calc_v_fold_marginal_ate.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the v-fold specifice ATE for each rule found for individual\nmixture components. — calc_v_fold_marginal_ate","title":"Calculate the v-fold specifice ATE for each rule found for individual\nmixture components. — calc_v_fold_marginal_ate","text":"Aggregate marginal rules mixture variable found across folds. rule extract relevant nuisance parameter data calculated folds. Given validation data estimates across folds, tree TMLE update step target average treatment effect. Update initial counterfactuals, calculate influence curve using influence curve calculate variance estimates p-values.","code":""},{"path":"/reference/calc_v_fold_marginal_ate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the v-fold specifice ATE for each rule found for individual\nmixture components. — calc_v_fold_marginal_ate","text":"","code":"calc_v_fold_marginal_ate(marginal_data, mix_comps, marginal_rules, y, n_folds)"},{"path":"/reference/calc_v_fold_marginal_ate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the v-fold specifice ATE for each rule found for individual\nmixture components. — calc_v_fold_marginal_ate","text":"marginal_data List dataframes nuisance parameter data mixture mix_comps Vector characters indicating mixture components marginal_rules List dataframes marginal rules found across folds y Vector indicating Y n_folds Number folds used cross-validation","code":""},{"path":"/reference/calc_v_fold_marginal_ate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the v-fold specifice ATE for each rule found for individual\nmixture components. — calc_v_fold_marginal_ate","text":"list marginal results fold including: marginal_results: data frame data adpatively determined mixture component thresholds rows ATE, variance, RMSE estimates columns. data: list data frames mixture component threshold evaluated exposure, baseline covariates, outcome, nuisance parameter estimates, marginal ATE influence curve.","code":""},{"path":"/reference/calc_v_fold_mixtures_ate.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the ATE for V-fold specific rules — calc_v_fold_mixtures_ate","title":"Calculate the ATE for V-fold specific rules — calc_v_fold_mixtures_ate","text":"rule fold extract relevant nuisance parameter data calculated folds. Given validation data estimates rule TMLE update step target average treatment effect. Update initial counterfactuals,calculate influence curve using influence curve calculate variance estimates p-values.","code":""},{"path":"/reference/calc_v_fold_mixtures_ate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the ATE for V-fold specific rules — calc_v_fold_mixtures_ate","text":"","code":"calc_v_fold_mixtures_ate(input_mix_rules, input_mix_data, y, n_folds)"},{"path":"/reference/calc_v_fold_mixtures_ate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the ATE for V-fold specific rules — calc_v_fold_mixtures_ate","text":"input_mix_rules List dataframes rules found mixture across folds input_mix_data Nuisance parameter data mixture rules found across folds y Character indicating outcome variable n_folds Number folds used cross-validation","code":""},{"path":"/reference/calc_v_fold_mixtures_ate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the ATE for V-fold specific rules — calc_v_fold_mixtures_ate","text":"data frame mixture results variable level combination fold","code":""},{"path":"/reference/calculatePooledEstimate.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculates the Inverse Variance Pooled Estimate Including Null Folds — calculatePooledEstimate","title":"Calculates the Inverse Variance Pooled Estimate Including Null Folds — calculatePooledEstimate","text":"weighted combination estimate folds estimates null folds finding 0 using inverse variance","code":""},{"path":"/reference/calculatePooledEstimate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculates the Inverse Variance Pooled Estimate Including Null Folds — calculatePooledEstimate","text":"","code":"calculatePooledEstimate(est, se, n_folds, n_intxn)"},{"path":"/reference/calculatePooledEstimate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculates the Inverse Variance Pooled Estimate Including Null Folds — calculatePooledEstimate","text":"n_folds Total number folds specified results_df Table results","code":""},{"path":"/reference/common_mixture_rules.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the union rule. This is the rule that covers all observations\nacross the folds. — common_mixture_rules","title":"Estimate the union rule. This is the rule that covers all observations\nacross the folds. — common_mixture_rules","text":"function takes list rules grouped variable sets. rules different variable sets may slightly different across folds make union rule variable set. entails creating new rule essentially: (rule fold 1) (rule fold 2) (rule fold 3) etc. evaluate rule input data create binary indicator union rule. , variables used rule, find min max regions indicated rule variable. put together statements create union rule.","code":""},{"path":"/reference/common_mixture_rules.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the union rule. This is the rule that covers all observations\nacross the folds. — common_mixture_rules","text":"","code":"common_mixture_rules(   group_list,   data = data,   mix_comps = mix_comps,   mixture_results,   n_folds,   no_mixture_rules )"},{"path":"/reference/common_mixture_rules.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the union rule. This is the rule that covers all observations\nacross the folds. — common_mixture_rules","text":"group_list List dataframes grouped rules variable sets data Full data mix_comps Mixture components mixture_results data frame results found mixture rules n_folds Number folds used cross-validation no_mixture_rules TRUE/FALSE mixture rule found","code":""},{"path":"/reference/common_mixture_rules.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the union rule. This is the rule that covers all observations\nacross the folds. — common_mixture_rules","text":"Rules object. TODO: add detail . Data frame mixture results including union rule proportion found across folds","code":""},{"path":"/reference/compute_meta_marg_results.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute v-fold specific estimates and do a meta-analysis type pooled\naverage ATE for each individual marginal rule. — compute_meta_marg_results","title":"Compute v-fold specific estimates and do a meta-analysis type pooled\naverage ATE for each individual marginal rule. — compute_meta_marg_results","text":"fold, estimates ATE fold specific mixture rule. Also estimates meta-analysis type average ATE pooled variance. Creates union rule covers folds rules.","code":""},{"path":"/reference/compute_meta_marg_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute v-fold specific estimates and do a meta-analysis type pooled\naverage ATE for each individual marginal rule. — compute_meta_marg_results","text":"","code":"compute_meta_marg_results(v_fold_marginal_results, data, mix_comps, n_folds)"},{"path":"/reference/compute_meta_marg_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute v-fold specific estimates and do a meta-analysis type pooled\naverage ATE for each individual marginal rule. — compute_meta_marg_results","text":"v_fold_marginal_results List dataframes v-fold specific estimates fold-specific rule results marginals data Input dataframe evaluate rules mix_comps Vector characters indicating mixture components n_folds Number folds used cross-validation","code":""},{"path":"/reference/compute_meta_marg_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute v-fold specific estimates and do a meta-analysis type pooled\naverage ATE for each individual marginal rule. — compute_meta_marg_results","text":"Rules object. TODO: add detail .","code":""},{"path":"/reference/compute_meta_mix_results.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute v-fold specific estimates and do a meta-analysis type pooled average ATE for mixture rules. — compute_meta_mix_results","title":"Compute v-fold specific estimates and do a meta-analysis type pooled average ATE for mixture rules. — compute_meta_mix_results","text":"fold, estimates ATE fold specific mixture rule. Also estimates meta-analysis type average ATE pooled variance. Creates union rule covers folds rules.","code":""},{"path":"/reference/compute_meta_mix_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute v-fold specific estimates and do a meta-analysis type pooled average ATE for mixture rules. — compute_meta_mix_results","text":"","code":"compute_meta_mix_results(v_fold_mixture_results, mix_comps, n_folds, data)"},{"path":"/reference/compute_meta_mix_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute v-fold specific estimates and do a meta-analysis type pooled average ATE for mixture rules. — compute_meta_mix_results","text":"v_fold_mixture_results List dataframes v-fold specific estimates fold-specific rule results mix_comps Vector characters indicating mixture components n_folds Number folds used cross-validation data Input dataframe evaluate rules","code":""},{"path":"/reference/compute_meta_mix_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute v-fold specific estimates and do a meta-analysis type pooled average ATE for mixture rules. — compute_meta_mix_results","text":"Rules object. TODO: add detail .","code":""},{"path":"/reference/create_cv_folds.html","id":null,"dir":"Reference","previous_headings":"","what":"Stratified CV to insure balance (by one grouping variable, Y) — create_cv_folds","title":"Stratified CV to insure balance (by one grouping variable, Y) — create_cv_folds","text":"Creates dummy variable partitions data v equal sized groups v-fold CV.","code":""},{"path":"/reference/create_cv_folds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stratified CV to insure balance (by one grouping variable, Y) — create_cv_folds","text":"","code":"create_cv_folds(v, y, verbose = FALSE)"},{"path":"/reference/create_cv_folds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stratified CV to insure balance (by one grouping variable, Y) — create_cv_folds","text":"v number folds y Outcome variable. binary used stratification. verbose T display extra output.","code":""},{"path":"/reference/create_cv_folds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stratified CV to insure balance (by one grouping variable, Y) — create_cv_folds","text":"Vector fold assignments.","code":""},{"path":"/reference/create_rules.html","id":null,"dir":"Reference","previous_headings":"","what":"From HAL fit, create string based rules — create_rules","title":"From HAL fit, create string based rules — create_rules","text":"HAL fit, create string based rules","code":""},{"path":"/reference/create_rules.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"From HAL fit, create string based rules — create_rules","text":"","code":"create_rules(basis_list, col_names)"},{"path":"/reference/create_rules.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"From HAL fit, create string based rules — create_rules","text":"basis_list Basis list HAL col_names Column names","code":""},{"path":"/reference/create_rules.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"From HAL fit, create string based rules — create_rules","text":"Inputs basis list HAL returns list rules","code":""},{"path":"/reference/create_sls.html","id":null,"dir":"Reference","previous_headings":"","what":"Create default Super Learner estimators for the data adaptive\nand nuisance parameters used in CVtreeMLE — create_sls","title":"Create default Super Learner estimators for the data adaptive\nand nuisance parameters used in CVtreeMLE — create_sls","text":"Super Learners passed stack arguments function used create default ensemble machine learning estimators parameter. default estimators fast also flexible.","code":""},{"path":"/reference/create_sls.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create default Super Learner estimators for the data adaptive\nand nuisance parameters used in CVtreeMLE — create_sls","text":"","code":"create_sls()"},{"path":"/reference/create_sls.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create default Super Learner estimators for the data adaptive\nand nuisance parameters used in CVtreeMLE — create_sls","text":"List ensemble estimators","code":""},{"path":"/reference/est_comb_exposure.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate the expected outcome for the combination of marginal\nthresholds identified in the fold. — est_comb_exposure","title":"Estimate the expected outcome for the combination of marginal\nthresholds identified in the fold. — est_comb_exposure","text":"Estimate expected outcome given exposure combination marginal exposures. different compared cumulative sum; whereas cumulative sum, exposure additive effect marginal rule found fold, marginal rule included Super Learner binary vector therefore can pick possible nonlinearity combination binary exposures.","code":""},{"path":"/reference/est_comb_exposure.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate the expected outcome for the combination of marginal\nthresholds identified in the fold. — est_comb_exposure","text":"","code":"est_comb_exposure(   at,   av,   y,   w,   marg_rule_train,   marg_rule_valid,   no_marg_rules,   aw_stack,   family,   parallel_cv,   seed )"},{"path":"/reference/est_comb_exposure.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate the expected outcome for the combination of marginal\nthresholds identified in the fold. — est_comb_exposure","text":"Training data av Validation data y Outcome variable w Vector characters denoting covariates marg_rule_train Data frame binary vectors marginal rules identified training fold marg_rule_valid Data frame binary vectors marginal rules identified validation fold no_marg_rules TRUE/FALSE marginal rules found across aw_stack Super Learner library fitting Q (outcome mechanism) g (treatment mechanism) family Outcome type family parallel_cv TRUE/FALSE parallel CV used seed Seed number folds","code":""},{"path":"/reference/est_comb_exposure.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate the expected outcome for the combination of marginal\nthresholds identified in the fold. — est_comb_exposure","text":"list combination marginal results within fold including: data: data frame marginal rules evaluated binary vectors, baseline covariates predicted outcomes given ensemble fitting. learner: Super Learner model fit data.","code":""},{"path":"/reference/est_marg_nuisance_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate nuisance parameters for each marginal mixture component — est_marg_nuisance_params","title":"Estimate nuisance parameters for each marginal mixture component — est_marg_nuisance_params","text":"marginal mixture component rule found, create g estimator probability exposed rule thresholds, Q estimator outcome E(Y| = a_mix, W). Get estimates g Q using validation data calculate clever covariate used TMLE fluctuation step.","code":""},{"path":"/reference/est_marg_nuisance_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate nuisance parameters for each marginal mixture component — est_marg_nuisance_params","text":"","code":"est_marg_nuisance_params(   at,   av,   w,   y,   aw_stack,   family,   a,   no_marg_rules,   marg_decisions,   parallel_cv,   seed,   h_aw_trunc_lvl )"},{"path":"/reference/est_marg_nuisance_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate nuisance parameters for each marginal mixture component — est_marg_nuisance_params","text":"Training data av Validation data w Vector characters denoting covariates y Outcome variable aw_stack Super Learner library fitting Q (outcome mechanism) g (treatment mechanism) family Binomial continuous Vector characters denote mixture components no_marg_rules TRUE/FALSE marginal rules found across folds marg_decisions List rules found within fold mixture component parallel_cv TRUE/FALSE cv parallelization used seed Seed number h_aw_trunc_lvl Truncation level clever covariate (induces bias reduce variance)","code":""},{"path":"/reference/est_marg_nuisance_params.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate nuisance parameters for each marginal mixture component — est_marg_nuisance_params","text":"marginal_data: list data frames mixture component baseline covariates, exposure, outcome, nuisance parameters needed calculate ATE.","code":""},{"path":"/reference/est_mix_nuisance_params.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimate nuisance parameters for each mixture interaction identified — est_mix_nuisance_params","title":"Estimate nuisance parameters for each mixture interaction identified — est_mix_nuisance_params","text":"mixture mixture interaction found, create g estimator probability exposed rule thresholds, Q estimator outcome E(Y| = a_mix, W). Get estimates g Q using validation data calculate clever covariate used TMLE fluctuation step.","code":""},{"path":"/reference/est_mix_nuisance_params.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimate nuisance parameters for each mixture interaction identified — est_mix_nuisance_params","text":"","code":"est_mix_nuisance_params(   at,   av,   w,   a,   y,   aw_stack,   family,   rules,   parallel_cv,   seed,   h_aw_trunc_lvl )"},{"path":"/reference/est_mix_nuisance_params.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimate nuisance parameters for each mixture interaction identified — est_mix_nuisance_params","text":"Training data av Validation data w Vector characters denoting covariates y outcome variable aw_stack Super Learner library fitting Q (outcome mechanism) g (treatment mechanism) family Binomial continuous rules Dataframe rules found PRE fitting process parallel_cv TRUE/FALSE cv parallelization used seed Seed number h_aw_trunc_lvl Truncation level clever covariate (induces bias reduce variance) no_mix_rules TRUE/FALSE indicator mixture rules found","code":""},{"path":"/reference/est_mix_nuisance_params.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimate nuisance parameters for each mixture interaction identified — est_mix_nuisance_params","text":"list dataframes nuisance parameters added raw data.","code":""},{"path":"/reference/evaluate_marginal_rules.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate mixture rules found during the rpart decision tree process — evaluate_marginal_rules","title":"Evaluate mixture rules found during the rpart decision tree process — evaluate_marginal_rules","text":"Evaluate mixture rules found rpart decision tree process","code":""},{"path":"/reference/evaluate_marginal_rules.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate mixture rules found during the rpart decision tree process — evaluate_marginal_rules","text":"","code":"evaluate_marginal_rules(data, marg_decisions, no_marg_rules, mix_comps)"},{"path":"/reference/evaluate_marginal_rules.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate mixture rules found during the rpart decision tree process — evaluate_marginal_rules","text":"data Input data marg_decisions List rules determined mixture component no_marg_rules TRUE/FALSE marginal rules found across folds mix_comps Vector characters denoting mixture components","code":""},{"path":"/reference/evaluate_marginal_rules.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate mixture rules found during the rpart decision tree process — evaluate_marginal_rules","text":"list marginal rules evaluated includes: data: fold raw data sum evaluated rule binary vectors mixture component added. marg_rule_df: binary matrix marginal rule evaluated binary vector.","code":""},{"path":"/reference/evaluate_mixture_rules.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate mixture rules found during the PRE process — evaluate_mixture_rules","title":"Evaluate mixture rules found during the PRE process — evaluate_mixture_rules","text":"Evaluate mixture rules found PRE process","code":""},{"path":"/reference/evaluate_mixture_rules.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate mixture rules found during the PRE process — evaluate_mixture_rules","text":"","code":"evaluate_mixture_rules(data, rules)"},{"path":"/reference/evaluate_mixture_rules.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate mixture rules found during the PRE process — evaluate_mixture_rules","text":"data Input data rules Dataframe rules determined","code":""},{"path":"/reference/evaluate_mixture_rules.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate mixture rules found during the PRE process — evaluate_mixture_rules","text":"binary_rule_matrix: binary matrix column mixture rule evaluated binary vector.","code":""},{"path":"/reference/evaluate_rules_to_binary.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate Rules to Binary Indicators — evaluate_rules_to_binary","title":"Evaluate Rules to Binary Indicators — evaluate_rules_to_binary","text":"Evaluate Rules Binary Indicators","code":""},{"path":"/reference/evaluate_rules_to_binary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate Rules to Binary Indicators — evaluate_rules_to_binary","text":"","code":"evaluate_rules_to_binary(rules, data, Y)"},{"path":"/reference/evaluate_rules_to_binary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate Rules to Binary Indicators — evaluate_rules_to_binary","text":"rules List rules data Data evaluate rules Y Outcome appended binary data","code":""},{"path":"/reference/evaluate_rules_to_binary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate Rules to Binary Indicators — evaluate_rules_to_binary","text":"Takes list rules outputs binary matrix","code":""},{"path":"/reference/filter_marginal_rules.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter marginal rules across the folds for only those that\nhave the same variables — filter_marginal_rules","title":"Filter marginal rules across the folds for only those that\nhave the same variables — filter_marginal_rules","text":"Filter marginal rules across folds variables","code":""},{"path":"/reference/filter_marginal_rules.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter marginal rules across the folds for only those that\nhave the same variables — filter_marginal_rules","text":"","code":"filter_marginal_rules(data, n_folds)"},{"path":"/reference/filter_marginal_rules.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter marginal rules across the folds for only those that\nhave the same variables — filter_marginal_rules","text":"data Input data n_folds Number folds CV","code":""},{"path":"/reference/filter_mixture_rules.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter mixture rules across the folds for only those that have the\nsame variables and directions across all folds — filter_mixture_rules","title":"Filter mixture rules across the folds for only those that have the\nsame variables and directions across all folds — filter_mixture_rules","text":"Filter mixture rules across folds variables directions across folds","code":""},{"path":"/reference/filter_mixture_rules.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter mixture rules across the folds for only those that have the\nsame variables and directions across all folds — filter_mixture_rules","text":"","code":"filter_mixture_rules(data, n_folds)"},{"path":"/reference/filter_mixture_rules.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter mixture rules across the folds for only those that have the\nsame variables and directions across all folds — filter_mixture_rules","text":"data Input data n_folds Number folds CV","code":""},{"path":"/reference/filter_rules.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter data based on fold — filter_rules","title":"Filter data based on fold — filter_rules","text":"Filter data based fold","code":""},{"path":"/reference/filter_rules.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter data based on fold — filter_rules","text":"","code":"filter_rules(data, fold_k)"},{"path":"/reference/filter_rules.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter data based on fold — filter_rules","text":"data Input data fold_k Current fold","code":""},{"path":"/reference/filter_rules.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Filter data based on fold — filter_rules","text":"Filter data training fold interest CV","code":""},{"path":"/reference/find_common_marginal_rules.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new rule based on observations that meet every rule across\nthe folds for each mixture. — find_common_marginal_rules","title":"Create a new rule based on observations that meet every rule across\nthe folds for each mixture. — find_common_marginal_rules","text":"mixture component, different rule found fold. Therefore, necessary create one rule mixture component can interpreted common rule across folds. , observations meet rules folds determined. new rule created observations. Specifically, put statements rules found across folds look min max values new region encompasses observations across folds.","code":""},{"path":"/reference/find_common_marginal_rules.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new rule based on observations that meet every rule across\nthe folds for each mixture. — find_common_marginal_rules","text":"","code":"find_common_marginal_rules(   fold_rules,   data,   mix_comps,   marginal_results,   n_folds )"},{"path":"/reference/find_common_marginal_rules.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a new rule based on observations that meet every rule across\nthe folds for each mixture. — find_common_marginal_rules","text":"fold_rules List rules found mixture component found across folds data Full data rules evaluated mix_comps Vector mixture components marginal_results Data frame holding results marginal component rule n_folds Total number folds","code":""},{"path":"/reference/find_common_marginal_rules.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a new rule based on observations that meet every rule across\nthe folds for each mixture. — find_common_marginal_rules","text":"Data frame rules, threshold regions, proportion folds min/max values","code":""},{"path":"/reference/fit_iterative_marg_rule_backfitting.html","id":null,"dir":"Reference","previous_headings":"","what":"Iteratively Backfit a Super Learner, h(x) = Y|M_neX,W, and Indiviidual Decision Algorithms, g(x), for each Y|M_x until Convergence. — fit_iterative_marg_rule_backfitting","title":"Iteratively Backfit a Super Learner, h(x) = Y|M_neX,W, and Indiviidual Decision Algorithms, g(x), for each Y|M_x until Convergence. — fit_iterative_marg_rule_backfitting","text":"Iteratively Backfit Super Learner, h(x) = Y|M_neX,W, Indiviidual Decision Algorithms, g(x), Y|M_x Convergence.","code":""},{"path":"/reference/fit_iterative_marg_rule_backfitting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Iteratively Backfit a Super Learner, h(x) = Y|M_neX,W, and Indiviidual Decision Algorithms, g(x), for each Y|M_x until Convergence. — fit_iterative_marg_rule_backfitting","text":"","code":"fit_iterative_marg_rule_backfitting(   mix_comps,   At,   W,   Q1_stack,   tree_SL,   fold,   max_iter,   verbose )"},{"path":"/reference/fit_iterative_marg_rule_backfitting.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Iteratively Backfit a Super Learner, h(x) = Y|M_neX,W, and Indiviidual Decision Algorithms, g(x), for each Y|M_x until Convergence. — fit_iterative_marg_rule_backfitting","text":"mix_comps vector characters indicating variables mixture components Training data W vector characters indicating variables covariates#' Q1_stack Stack algorithms made SL 3 used ensemble machine learning fit Y|W tree_SL Stack algorithms made SL decision tree estimation fold Current fold cross-validation max_iter Max number iterations iterative backfitting algorithm verbose Run verbose setting","code":""},{"path":"/reference/fit_iterative_marg_rule_backfitting.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Iteratively Backfit a Super Learner, h(x) = Y|M_neX,W, and Indiviidual Decision Algorithms, g(x), for each Y|M_x until Convergence. — fit_iterative_marg_rule_backfitting","text":"Rules object. TODO: add detail .","code":""},{"path":"/reference/fit_iterative_marg_rule_backfitting.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Iteratively Backfit a Super Learner, h(x) = Y|M_neX,W, and Indiviidual Decision Algorithms, g(x), for each Y|M_x until Convergence. — fit_iterative_marg_rule_backfitting","text":"procedure fit_iterative_mix_rule_backfitting Super Learner controls W mixture variables equal mixture variable interest, glmtree used find partitions instead pre.","code":""},{"path":"/reference/fit_iterative_mix_rule_backfitting.html","id":null,"dir":"Reference","previous_headings":"","what":"Iteratively Backfit a Super Learner, h(x) = Y|W, and an Ensemble Decision Algorithm, g(x), Y|M_x until Convergence. — fit_iterative_mix_rule_backfitting","title":"Iteratively Backfit a Super Learner, h(x) = Y|W, and an Ensemble Decision Algorithm, g(x), Y|M_x until Convergence. — fit_iterative_mix_rule_backfitting","text":"Iteratively Backfit Super Learner, h(x) = Y|W, Ensemble Decision Algorithm, g(x), Y|M_x Convergence.","code":""},{"path":"/reference/fit_iterative_mix_rule_backfitting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Iteratively Backfit a Super Learner, h(x) = Y|W, and an Ensemble Decision Algorithm, g(x), Y|M_x until Convergence. — fit_iterative_mix_rule_backfitting","text":"","code":"fit_iterative_mix_rule_backfitting(   At,   A,   W,   Y,   Q1_stack,   fold,   max_iter,   verbose )"},{"path":"/reference/fit_iterative_mix_rule_backfitting.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Iteratively Backfit a Super Learner, h(x) = Y|W, and an Ensemble Decision Algorithm, g(x), Y|M_x until Convergence. — fit_iterative_mix_rule_backfitting","text":"Training dataframe Variable names mixture W Variable names covariates Y Variable name outcome Q1_stack Stack algorithms made SL 3 used ensemble machine learning fit Y|W fold Current fold cross-validation max_iter Max number iterations iterative backfitting algorithm verbose Run verbose setting","code":""},{"path":"/reference/fit_iterative_mix_rule_backfitting.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Iteratively Backfit a Super Learner, h(x) = Y|W, and an Ensemble Decision Algorithm, g(x), Y|M_x until Convergence. — fit_iterative_mix_rule_backfitting","text":"Rules object. TODO: add detail .","code":""},{"path":"/reference/fit_iterative_mix_rule_backfitting.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Iteratively Backfit a Super Learner, h(x) = Y|W, and an Ensemble Decision Algorithm, g(x), Y|M_x until Convergence. — fit_iterative_mix_rule_backfitting","text":"Performs iterative backfitting algorithm flexibly adjust covariates W finding best fitting set mixture rules partition space M.","code":""},{"path":"/reference/fit_least_fav_submodel.html","id":null,"dir":"Reference","previous_headings":"","what":"Least Favorable Submodel — fit_least_fav_submodel","title":"Least Favorable Submodel — fit_least_fav_submodel","text":"Least Favorable Submodel","code":""},{"path":"/reference/fit_least_fav_submodel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Least Favorable Submodel — fit_least_fav_submodel","text":"","code":"fit_least_fav_submodel(h_aw, data, y, qbar_aw, qbar_1w)"},{"path":"/reference/fit_least_fav_submodel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Least Favorable Submodel — fit_least_fav_submodel","text":"h_aw numeric vector values clever covariate data dataframe includes treatement/exposure y Outcome variable used fluctuation model qbar_aw Initial predictions Y|,W - observed qbar_1w Initial predictions Y|= 1,W - deterministically set 1 qbar_0w Initial predictions Y|= 1,W - deterministically set 0","code":""},{"path":"/reference/fit_least_fav_submodel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Least Favorable Submodel — fit_least_fav_submodel","text":"numeric vector length vals, returned values bounded machine precision. intended avoid numerical instability issues.","code":""},{"path":"/reference/fit_least_fav_submodel.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Least Favorable Submodel — fit_least_fav_submodel","text":"flucutation initial outcome estimates using least favorable submodel TMLE update step","code":""},{"path":"/reference/fit_marg_rule_backfitting.html","id":null,"dir":"Reference","previous_headings":"","what":"Iteratively back-fit a Super Learner on marginal mixture components\nand covariates — fit_marg_rule_backfitting","title":"Iteratively back-fit a Super Learner on marginal mixture components\nand covariates — fit_marg_rule_backfitting","text":"Iteratively back-fit Super Learner marginal mixture components covariates","code":""},{"path":"/reference/fit_marg_rule_backfitting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Iteratively back-fit a Super Learner on marginal mixture components\nand covariates — fit_marg_rule_backfitting","text":"","code":"fit_marg_rule_backfitting(   mix_comps,   at,   w,   y,   w_stack,   tree_stack,   fold,   max_iter,   verbose,   parallel_cv,   seed )"},{"path":"/reference/fit_marg_rule_backfitting.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Iteratively back-fit a Super Learner on marginal mixture components\nand covariates — fit_marg_rule_backfitting","text":"mix_comps vector characters indicating variables mixture components Training data w vector characters indicating variables covariates y outcome variable name w_stack Stack algorithms made SL 3 used ensemble machine learning fit Y|W tree_stack Stack algorithms made SL decision tree estimation fold Current fold cross-validation max_iter Max number iterations iterative backfitting algorithm verbose Run verbose setting parallel_cv Parallelize cross-validation (TRUE/FALSE) seed Numeric, seed number consistent results","code":""},{"path":"/reference/fit_marg_rule_backfitting.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Iteratively back-fit a Super Learner on marginal mixture components\nand covariates — fit_marg_rule_backfitting","text":"list marginal rule results within fold including: marginal_df: data frame data adaptively determined rules found partykit model along coefficients measures. models: best fitting partykit model found mixture component fold.","code":""},{"path":"/reference/fit_marg_rule_backfitting.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Iteratively back-fit a Super Learner on marginal mixture components\nand covariates — fit_marg_rule_backfitting","text":"Fit semi-parametric additive model E(Y) = f() + h(W) f() Super Learner decision trees applied mixture component h(W) Super Learner applied covariates. estimator fit offset predictions convergence convergence essentially difference model fits. partitioning set found f() return rules data-adaptively identified thresholds mixture component maximize group difference controlling covariates.","code":""},{"path":"/reference/fit_marg_rule_backfitting.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Iteratively back-fit a Super Learner on marginal mixture components\nand covariates — fit_marg_rule_backfitting","text":"","code":"data <- simulate_mixture_cube() mix_comps <- c(\"M1\", \"M2\", \"M3\") w <- c(\"age\", \"sex\", \"bmi\") sls <- create_sls() w_stack <- sls$W_stack tree_stack <- sls$A_stack example_output <- fit_marg_rule_backfitting(   mix_comps = mix_comps,   at = data,   w = w,   y = \"y\",   w_stack = w_stack,   tree_stack = tree_stack,   fold = 1,   verbose = FALSE,   parallel_cv = FALSE,   seed = 6442 ) #> Warning: coercing argument of type 'list' to logical #> Error in initialize(...): 'list' object cannot be coerced to type 'logical'"},{"path":"/reference/fit_min_ave_tree_algorithm.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit minimum average tree — fit_min_ave_tree_algorithm","title":"Fit minimum average tree — fit_min_ave_tree_algorithm","text":"Fit minimum average tree","code":""},{"path":"/reference/fit_min_ave_tree_algorithm.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit minimum average tree — fit_min_ave_tree_algorithm","text":"","code":"fit_min_ave_tree_algorithm(   at,   a,   w,   y,   family,   fold,   parallel_cv,   min_max,   min_obs )"},{"path":"/reference/fit_min_ave_tree_algorithm.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit minimum average tree — fit_min_ave_tree_algorithm","text":"Training dataframe Variable names mixture w Variable names covariates y Variable name outcome fold Current fold cross-validation parallel_cv TRUE/FALSE indicator parallelize cv direction Positive/negative - max min coefficient keep ensemble w_stack Stack algorithms made SL 3 used ensemble machine learning fit Y|W max_iter Max number iterations iterative backfitting algorithm verbose Run verbose setting seed Seed number consistent results","code":""},{"path":"/reference/fit_min_ave_tree_algorithm.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit minimum average tree — fit_min_ave_tree_algorithm","text":"list mixture rule results within fold including: rules: data frame data adpatively determined rules found pre model along coefficient, direction, fold, RMSE measures. model: best fitting pre model found fold.","code":""},{"path":"/reference/fit_min_ave_tree_algorithm.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit minimum average tree — fit_min_ave_tree_algorithm","text":"Fits min ave tree","code":""},{"path":"/reference/fit_min_ave_tree_algorithm.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit minimum average tree — fit_min_ave_tree_algorithm","text":"","code":"data <- simulate_mixture_cube() mix_comps <- c(\"M1\", \"M2\", \"M3\") W <- c(\"age\", \"sex\", \"bmi\") sls <- create_sls() w_stack <- sls$W_stack tree_stack <- sls$A_stack example_output <- fit_pre_algorithm(   at = data,   a = mix_comps,   w = W,   y = \"y\",   direction = \"positive\",   w_stack = w_stack,   fold = 1,   max_iter = 1,   verbose = FALSE,   parallel = FALSE,   seed = 6442 ) #> Error in fit_pre_algorithm(at = data, a = mix_comps, w = W, y = \"y\", direction = \"positive\",     w_stack = w_stack, fold = 1, max_iter = 1, verbose = FALSE,     parallel = FALSE, seed = 6442): could not find function \"fit_pre_algorithm\""},{"path":"/reference/fit_mix_rule_backfitting.html","id":null,"dir":"Reference","previous_headings":"","what":"Iteratively Backfit a Super Learner, h(x) = Y|W, and an Ensemble\nDecision Algorithm, g(x), Y|M_x until Convergence. — fit_mix_rule_backfitting","title":"Iteratively Backfit a Super Learner, h(x) = Y|W, and an Ensemble\nDecision Algorithm, g(x), Y|M_x until Convergence. — fit_mix_rule_backfitting","text":"Iteratively Backfit Super Learner, h(x) = Y|W, Ensemble Decision Algorithm, g(x), Y|M_x Convergence.","code":""},{"path":"/reference/fit_mix_rule_backfitting.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Iteratively Backfit a Super Learner, h(x) = Y|W, and an Ensemble\nDecision Algorithm, g(x), Y|M_x until Convergence. — fit_mix_rule_backfitting","text":"","code":"fit_mix_rule_backfitting(   at,   a,   w,   y,   direction,   w_stack,   fold,   max_iter,   verbose,   parallel_cv,   seed )"},{"path":"/reference/fit_mix_rule_backfitting.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Iteratively Backfit a Super Learner, h(x) = Y|W, and an Ensemble\nDecision Algorithm, g(x), Y|M_x until Convergence. — fit_mix_rule_backfitting","text":"Training dataframe Variable names mixture w Variable names covariates y Variable name outcome direction Positive/negative - max min coefficient keep ensemble w_stack Stack algorithms made SL 3 used ensemble machine learning fit Y|W fold Current fold cross-validation max_iter Max number iterations iterative backfitting algorithm verbose Run verbose setting parallel_cv TRUE/FALSE indicator parallelize cv seed Seed number consistent results","code":""},{"path":"/reference/fit_mix_rule_backfitting.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Iteratively Backfit a Super Learner, h(x) = Y|W, and an Ensemble\nDecision Algorithm, g(x), Y|M_x until Convergence. — fit_mix_rule_backfitting","text":"list mixture rule results within fold including: rules: data frame data adpatively determined rules found pre model along coefficient, direction, fold, RMSE measures. model: best fitting pre model found fold.","code":""},{"path":"/reference/fit_mix_rule_backfitting.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Iteratively Backfit a Super Learner, h(x) = Y|W, and an Ensemble\nDecision Algorithm, g(x), Y|M_x until Convergence. — fit_mix_rule_backfitting","text":"Performs iterative backfitting algorithm flexibly adjust covariates W finding best fitting set mixture rules partition space M.","code":""},{"path":"/reference/fit_mix_rule_backfitting.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Iteratively Backfit a Super Learner, h(x) = Y|W, and an Ensemble\nDecision Algorithm, g(x), Y|M_x until Convergence. — fit_mix_rule_backfitting","text":"","code":"data <- simulate_mixture_cube() mix_comps <- c(\"M1\", \"M2\", \"M3\") W <- c(\"age\", \"sex\", \"bmi\") sls <- create_sls() w_stack <- sls$W_stack tree_stack <- sls$A_stack example_output <- fit_mix_rule_backfitting(   at = data,   a = mix_comps,   w = W,   y = \"y\",   direction = \"positive\",   w_stack = w_stack,   fold = 1,   max_iter = 1,   verbose = FALSE,   parallel = FALSE,   seed = 6442 )"},{"path":"/reference/format_RMSE_for_models.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates the RMSE output — format_RMSE_for_models","title":"Creates the RMSE output — format_RMSE_for_models","text":"Create simple data frame marginal, mixture, additive marginal non-additive marginal models root mean squared error.","code":""},{"path":"/reference/format_RMSE_for_models.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates the RMSE output — format_RMSE_for_models","text":"","code":"format_RMSE_for_models(   marginal_results,   mixture_results,   additive_RMSE_star,   marg_combo_data )"},{"path":"/reference/format_RMSE_for_models.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates the RMSE output — format_RMSE_for_models","text":"marginal_results Marginal results dataframe mixture_results Mixture results dataframe additive_RMSE_star Additive marginal model RMSE marg_combo_data Non-additive marginal dataframe","code":""},{"path":"/reference/groupby_fold.html","id":null,"dir":"Reference","previous_headings":"","what":"Group by fold — groupby_fold","title":"Group by fold — groupby_fold","text":"Group fold Group fold","code":""},{"path":"/reference/groupby_fold.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group by fold — groupby_fold","text":"","code":"groupby_fold(data)  groupby_fold(data)"},{"path":"/reference/groupby_fold.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group by fold — groupby_fold","text":"data Input data","code":""},{"path":"/reference/impute_NA_vals.html","id":null,"dir":"Reference","previous_headings":"","what":"Impute NA values and create indicator variables — impute_NA_vals","title":"Impute NA values and create indicator variables — impute_NA_vals","text":"Impute NA values create indicator variables","code":""},{"path":"/reference/impute_NA_vals.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Impute NA values and create indicator variables — impute_NA_vals","text":"","code":"impute_NA_vals(data, W)"},{"path":"/reference/impute_NA_vals.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Impute NA values and create indicator variables — impute_NA_vals","text":"data Input data W Vector covariates","code":""},{"path":"/reference/list.rules.party.html","id":null,"dir":"Reference","previous_headings":"","what":"Get rules from partykit object in rule fitting — list.rules.party","title":"Get rules from partykit object in rule fitting — list.rules.party","text":"Get rules partykit object rule fitting","code":""},{"path":"/reference/list.rules.party.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get rules from partykit object in rule fitting — list.rules.party","text":"","code":"list.rules.party(x, i = NULL, ...)"},{"path":"/reference/list.rules.party.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get rules from partykit object in rule fitting — list.rules.party","text":"x Partykit glmtree model object null ... additional arguments","code":""},{"path":"/reference/list.rules.party.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get rules from partykit object in rule fitting — list.rules.party","text":"List rules","code":""},{"path":"/reference/list_rules_party.html","id":null,"dir":"Reference","previous_headings":"","what":"Get rules from partykit object in rule fitting — list_rules_party","title":"Get rules from partykit object in rule fitting — list_rules_party","text":"Get rules partykit object rule fitting","code":""},{"path":"/reference/list_rules_party.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get rules from partykit object in rule fitting — list_rules_party","text":"","code":"list_rules_party(x, i = NULL, ...)"},{"path":"/reference/list_rules_party.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get rules from partykit object in rule fitting — list_rules_party","text":"x Partykit glmtree model object null ... additional arguments","code":""},{"path":"/reference/list_rules_party.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get rules from partykit object in rule fitting — list_rules_party","text":"List rules","code":""},{"path":"/reference/marginal_group_split.html","id":null,"dir":"Reference","previous_headings":"","what":"Group split by marginal variable — marginal_group_split","title":"Group split by marginal variable — marginal_group_split","text":"Group split marginal variable","code":""},{"path":"/reference/marginal_group_split.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Group split by marginal variable — marginal_group_split","text":"","code":"marginal_group_split(data)"},{"path":"/reference/marginal_group_split.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Group split by marginal variable — marginal_group_split","text":"data Input data","code":""},{"path":"/reference/meta_mix_results.html","id":null,"dir":"Reference","previous_headings":"","what":"Compute v-fold specific estimates and do a meta-analysis type\npooled average ATE for mixture rules. — meta_mix_results","title":"Compute v-fold specific estimates and do a meta-analysis type\npooled average ATE for mixture rules. — meta_mix_results","text":"fold, estimates ATE fold specific mixture rule. Also estimates meta-analysis type average ATE pooled variance. Creates union rule covers folds rules.","code":""},{"path":"/reference/meta_mix_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compute v-fold specific estimates and do a meta-analysis type\npooled average ATE for mixture rules. — meta_mix_results","text":"","code":"meta_mix_results(v_fold_mixture_results, mix_comps, n_folds, data)"},{"path":"/reference/meta_mix_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compute v-fold specific estimates and do a meta-analysis type\npooled average ATE for mixture rules. — meta_mix_results","text":"v_fold_mixture_results List dataframes v-fold specific estimates fold-specific rule results mix_comps Vector characters indicating mixture components n_folds Number folds used cross-validation data Input dataframe evaluate rules","code":""},{"path":"/reference/meta_mix_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compute v-fold specific estimates and do a meta-analysis type\npooled average ATE for mixture rules. — meta_mix_results","text":"v_fold_mixture_w_pooled: list grouped variable sets included rule pooled results added final row.","code":""},{"path":"/reference/plot_marginal_results.html","id":null,"dir":"Reference","previous_headings":"","what":"Create dot-whisker plots for the marginal results found — plot_marginal_results","title":"Create dot-whisker plots for the marginal results found — plot_marginal_results","text":"Create dot-whisker plots marginal results found","code":""},{"path":"/reference/plot_marginal_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create dot-whisker plots for the marginal results found — plot_marginal_results","text":"","code":"plot_marginal_results(v_marginal_results, mix_comps, hjust)"},{"path":"/reference/plot_marginal_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create dot-whisker plots for the marginal results found — plot_marginal_results","text":"v_marginal_results Table marginal results mixture components mix_comps Character list mixture variables hjust Degree horizontally adjust placement rules plot","code":""},{"path":"/reference/plot_mixture_results.html","id":null,"dir":"Reference","previous_headings":"","what":"Create dot-whisker plots for the mixture results found — plot_mixture_results","title":"Create dot-whisker plots for the mixture results found — plot_mixture_results","text":"Create dot-whisker plots mixture results found","code":""},{"path":"/reference/plot_mixture_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create dot-whisker plots for the mixture results found — plot_mixture_results","text":"","code":"plot_mixture_results(model, hjust)"},{"path":"/reference/plot_mixture_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create dot-whisker plots for the mixture results found — plot_mixture_results","text":"hjust Horizontal adjustment rule placement plots relative point estimate v_intxn_results Table interaction results mixture","code":""},{"path":"/reference/pull_out_rule_vars.html","id":null,"dir":"Reference","previous_headings":"","what":"Pull rules out of results table of pre results — pull_out_rule_vars","title":"Pull rules out of results table of pre results — pull_out_rule_vars","text":"Pull rules results table pre results","code":""},{"path":"/reference/pull_out_rule_vars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pull rules out of results table of pre results — pull_out_rule_vars","text":"","code":"pull_out_rule_vars(x, a)"},{"path":"/reference/pull_out_rule_vars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pull rules out of results table of pre results — pull_out_rule_vars","text":"x Row dataframe contains output pre fit Vector characters indicating column names mixture variables","code":""},{"path":"/reference/pull_out_rule_vars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pull rules out of results table of pre results — pull_out_rule_vars","text":"Vector matches mixture variables","code":""},{"path":"/reference/pull_out_rule_vars.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pull rules out of results table of pre results — pull_out_rule_vars","text":"Simply function looks variables used pre model matches mixture variables pulls check consistent sets rules found iterative backfitting procedure","code":""},{"path":"/reference/round_rules.html","id":null,"dir":"Reference","previous_headings":"","what":"Round rules found for easier reading — round_rules","title":"Round rules found for easier reading — round_rules","text":"Round rules found easier reading","code":""},{"path":"/reference/round_rules.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Round rules found for easier reading — round_rules","text":"","code":"round_rules(rules)"},{"path":"/reference/round_rules.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Round rules found for easier reading — round_rules","text":"rules Vector rules","code":""},{"path":"/reference/scale_to_original.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform Values From The Unit Interval Back To Their Original Scale — scale_to_original","title":"Transform Values From The Unit Interval Back To Their Original Scale — scale_to_original","text":"Transform Values Unit Interval Back Original Scale","code":""},{"path":"/reference/scale_to_original.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform Values From The Unit Interval Back To Their Original Scale — scale_to_original","text":"","code":"scale_to_original(scaled_vals, max_orig, min_orig)"},{"path":"/reference/scale_to_original.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform Values From The Unit Interval Back To Their Original Scale — scale_to_original","text":"scaled_vals numeric vector corresponding re-scaled values unit interval, re-scaled original interval. max_orig numeric scalar value giving maximum values original scale. min_orig numeric scalar value giving minimum values original scale.","code":""},{"path":"/reference/scale_to_original.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform Values From The Unit Interval Back To Their Original Scale — scale_to_original","text":"numeric vector length scaled_vals, values re-scaled lie original/natural interval.","code":""},{"path":"/reference/scale_to_original.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Transform Values From The Unit Interval Back To Their Original Scale — scale_to_original","text":"back-transformation returns values computed unit interval original scale. used re-scaling updated TML estimates back natural scale. Undoes scale_to_unit.","code":""},{"path":"/reference/scale_to_unit.html","id":null,"dir":"Reference","previous_headings":"","what":"Transform values by scaling to the unit interval — scale_to_unit","title":"Transform values by scaling to the unit interval — scale_to_unit","text":"Transform values scaling unit interval","code":""},{"path":"/reference/scale_to_unit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Transform values by scaling to the unit interval — scale_to_unit","text":"","code":"scale_to_unit(vals)"},{"path":"/reference/scale_to_unit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Transform values by scaling to the unit interval — scale_to_unit","text":"vals numeric vector corresponding observed values variable interest, re-scaled unit interval.","code":""},{"path":"/reference/scale_to_unit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Transform values by scaling to the unit interval — scale_to_unit","text":"numeric vector length vals, values re-scaled lay unit interval.","code":""},{"path":"/reference/scale_to_unit.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Transform values by scaling to the unit interval — scale_to_unit","text":"transformation scales arbitrary set input values unit interval. See scale_to_original corresponding backtransformation.","code":""},{"path":"/reference/simulate_mixture_cube.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate a mixture cube to test CVtreeMLE against simulated\nground-truth. — simulate_mixture_cube","title":"Simulate a mixture cube to test CVtreeMLE against simulated\nground-truth. — simulate_mixture_cube","text":"Simulate mixture cube. creates three correlated mixture variables associated two confounders W1 W2. First mixtures generated multivariate normal. multinomial outcome generated based betas input W1 W2 - associating W part mixture cube. part mixture cube, transform multivariate normal mixture uniform distribution, respecting bounds parts cube. three variable cube one threshold per variable 8 subspaces. outcome generated linear combination different subspaces.","code":""},{"path":"/reference/simulate_mixture_cube.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate a mixture cube to test CVtreeMLE against simulated\nground-truth. — simulate_mixture_cube","text":"","code":"simulate_mixture_cube(   n_obs = 500,   splits = c(0.99, 2, 2.5),   mins = c(0, 0, 0),   maxs = c(3, 4, 5),   mu = c(0, 0, 0),   sigma = matrix(c(1, 0.5, 0.8, 0.5, 1, 0.7, 0.8, 0.7, 1), nrow = 3, ncol = 3),   w1_betas = c(0, 0.01, 0.03, 0.06, 0.1, 0.05, 0.2, 0.04),   w2_betas = c(0, 0.04, 0.01, 0.07, 0.15, 0.1, 0.1, 0.04),   mix_subspace_betas = c(0, 0.08, 0.05, 0.01, 0.05, 0.033, 0.07, 0.09),   subspace_assoc_strength_betas = c(1, 1, 1, 1, 1, 1, 1, 7),   marginal_impact_betas = c(0, 0, 0),   eps_sd = 0.01,   binary = FALSE )"},{"path":"/reference/simulate_mixture_cube.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate a mixture cube to test CVtreeMLE against simulated\nground-truth. — simulate_mixture_cube","text":"n_obs Number observations generate data splits Vector indicating thresholds placed mixture variable mins Vector indicating minimum values mixture variable maxs Vector indicating maximum values mixture variable mu Vector indicating mean values mixture variable sigma Matrix variance-covariance structure used generate mixture variables w1_betas Vector betas define subspace probability relationship covariate W1 w2_betas Vector betas define subspace probability relationship covariate W2 mix_subspace_betas Vector betas define subspace probabilities subspace_assoc_strength_betas outcome Y generated partition mixture cube marginal_impact_betas Vector betas define marginal impact mixture variable eps_sd Random error included generation Y binary TRUE/FALSE depending outcome binary","code":""},{"path":"/reference/simulate_mixture_cube.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate a mixture cube to test CVtreeMLE against simulated\nground-truth. — simulate_mixture_cube","text":"obs: data frame simulated data mixture cube.","code":""},{"path":"/reference/v_fold_marginal_qgroup_split.html","id":null,"dir":"Reference","previous_headings":"","what":"v-fold marginal group split — v_fold_marginal_qgroup_split","title":"v-fold marginal group split — v_fold_marginal_qgroup_split","text":"v-fold marginal group split","code":""},{"path":"/reference/v_fold_marginal_qgroup_split.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"v-fold marginal group split — v_fold_marginal_qgroup_split","text":"","code":"v_fold_marginal_qgroup_split(data)"},{"path":"/reference/v_fold_marginal_qgroup_split.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"v-fold marginal group split — v_fold_marginal_qgroup_split","text":"data Input data","code":""},{"path":"/reference/v_fold_mixture_group_split.html","id":null,"dir":"Reference","previous_headings":"","what":"v-fold group split — v_fold_mixture_group_split","title":"v-fold group split — v_fold_mixture_group_split","text":"v-fold group split","code":""},{"path":"/reference/v_fold_mixture_group_split.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"v-fold group split — v_fold_mixture_group_split","text":"","code":"v_fold_mixture_group_split(data)"},{"path":"/reference/v_fold_mixture_group_split.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"v-fold group split — v_fold_mixture_group_split","text":"data Input data","code":""}]
