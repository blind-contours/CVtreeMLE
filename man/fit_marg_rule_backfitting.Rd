% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fit_iterative_marg_rule_backfitting.R
\name{fit_marg_rule_backfitting}
\alias{fit_marg_rule_backfitting}
\title{Iteratively back-fit a Super Learner on marginal mixture components
and covariates}
\usage{
fit_marg_rule_backfitting(
  mix_comps,
  at,
  w,
  y,
  w_stack,
  tree_stack,
  fold,
  max_iter,
  verbose,
  parallel_cv,
  seed
)
}
\arguments{
\item{mix_comps}{A vector of characters indicating variables for the
mixture components}

\item{at}{Training data}

\item{w}{A vector of characters indicating variables that are covariates}

\item{y}{The outcome variable name}

\item{w_stack}{Stack of algorithms made in SL 3 used in ensemble machine
learning to fit Y|W}

\item{tree_stack}{Stack of algorithms made in SL for the decision tree
estimation}

\item{fold}{Current fold in the cross-validation}

\item{max_iter}{Max number of iterations of iterative backfitting algorithm}

\item{verbose}{Run in verbose setting}

\item{parallel_cv}{Parallelize the cross-validation (TRUE/FALSE)}

\item{seed}{Numeric, seed number for consistent results}
}
\value{
A list of the marginal rule results within a fold including:
\itemize{
\item \code{marginal_df}: A data frame with the data adaptively
determined rules found in the \code{partykit} model along with
the coefficients and other measures.
\item \code{models}: The best fitting \code{partykit} model found for
each mixture component in the fold.
}
}
\description{
Iteratively back-fit a Super Learner on marginal mixture components
and covariates
}
\details{
Fit the semi-parametric additive model E(Y) = f(A) + h(W) where
f(A) is a Super Learner of decision trees applied to each mixture component
and h(W) is a Super Learner applied to the covariates. Each estimator is fit
offset by the predictions of the other until convergence where convergence
is essentially no difference between the model fits. If a partitioning set
is found in f(A) return the rules which are the data-adaptively identified
thresholds for the mixture component that maximize the between group
difference while controlling for covariates.
}
\examples{
data <- simulate_mixture_cube()
mix_comps <- c("M1", "M2", "M3")
w <- c("age", "sex", "bmi")
sls <- create_sls()
w_stack <- sls$W_stack
tree_stack <- sls$A_stack
example_output <- fit_marg_rule_backfitting(
  mix_comps = mix_comps,
  at = data,
  w = w,
  y = "y",
  w_stack = w_stack,
  tree_stack = tree_stack,
  fold = 1,
  verbose = FALSE,
  parallel_cv = FALSE,
  seed = 6442
)

}
